{"searchDocs":[{"title":"Din√°mica","type":0,"sectionRef":"#","url":"/apuntes-fundamentals/docs/Ciencias/dinamica","content":"Din√°mica","keywords":"","version":"Next"},{"title":"Electricidad y Magnetismo","type":0,"sectionRef":"#","url":"/apuntes-fundamentals/docs/Ciencias/electromagnetismo","content":"Electricidad y Magnetismo","keywords":"","version":"Next"},{"title":"Computaci√≥n","type":0,"sectionRef":"#","url":"/apuntes-fundamentals/docs/Ingenier√≠a/computacion","content":"Computaci√≥n","keywords":"","version":"Next"},{"title":"Termodin√°mica","type":0,"sectionRef":"#","url":"/apuntes-fundamentals/docs/Ciencias/termodinamica","content":"Termodin√°mica","keywords":"","version":"Next"},{"title":"Econom√≠a","type":0,"sectionRef":"#","url":"/apuntes-fundamentals/docs/Ingenier√≠a/economia","content":"Econom√≠a","keywords":"","version":"Next"},{"title":"√âtica","type":0,"sectionRef":"#","url":"/apuntes-fundamentals/docs/Ingenier√≠a/etica","content":"√âtica","keywords":"","version":"Next"},{"title":"Qu√≠mica","type":0,"sectionRef":"#","url":"/apuntes-fundamentals/docs/Ciencias/quimica","content":"Qu√≠mica","keywords":"","version":"Next"},{"title":"Ecuaciones diferenciales","type":0,"sectionRef":"#","url":"/apuntes-fundamentals/docs/Matem√°ticas/ecuaciones_diferenciales","content":"Ecuaciones diferenciales","keywords":"","version":"Next"},{"title":"Introducci√≥n","type":0,"sectionRef":"#","url":"/apuntes-fundamentals/docs/intro","content":"","keywords":"","version":"Next"},{"title":"Estructura del Examen‚Äã","type":1,"pageTitle":"Introducci√≥n","url":"/apuntes-fundamentals/docs/intro#estructura-del-examen","content":" El examen consta de 110 preguntas, distribuidas entre 3 pruebas. La distribuci√≥n de preguntas es la siguiente:  T√≥pico / Curso\tT√≥pico / Curso\tN¬∞ PreguntasMatem√°tica\tMAT1610 C√°lculo I\t2 Matem√°tica\tMAT1620 C√°lculo II\t4 Matem√°tica\tMAT1630 C√°lculo III\t4 Matem√°tica\tMAT1640 Ecuaciones Diferenciales\t4 Matem√°tica\tMAT1203 √Ålgebra Lineal\t4 Probabilidades y Estad√≠stica\tProbabilidades y Estad√≠stica\t12 Qu√≠mica\tQu√≠mica\t12 Computaci√≥n\tComputaci√≥n\t12 √âtica\t√âtica\t8 Econom√≠a\tEconom√≠a\t12 Din√°mica\tDin√°mica\t12 Electricidad y Magnetismo\tElectricidad y Magnetismo\t12 Termodin√°mica\tTermodin√°mica\t12 Total\t110  El examen se divide en 3 m√≥dulos: Matem√°ticas (M1), Ciencias (M2) e Ingenier√≠a (M3). Usualmente, se rinden los m√≥dulos M1 y M3 el primer d√≠a, y el m√≥dulo M2 el segundo d√≠a.  ","version":"Next","tagName":"h2"},{"title":"Contenidos y detalles‚Äã","type":1,"pageTitle":"Introducci√≥n","url":"/apuntes-fundamentals/docs/intro#contenidos-y-detalles","content":" info Estas tablas fueron copiadas directamente de SIDING. Eventualmente ser√°n escritas de una manera m√°s elegante y legible. üóø  A continuaci√≥n, se detallan los contenidos espec√≠ficos de cada m√≥dulo.  ","version":"Next","tagName":"h2"},{"title":"Matem√°ticas (M1)‚Äã","type":1,"pageTitle":"Introducci√≥n","url":"/apuntes-fundamentals/docs/intro#matem√°ticas-m1","content":" Esta prueba tiene 30 preguntas y tiene una duraci√≥n de 2 horas. Los contenidos son:  T√≥pico\tCurso\tContenidos\tIndicadores a evaluar (N√∫meros corresponden al correlativo del programa de cada curso)Matem√°ticas\tMAT1610 C√°lculo I 1. Geometr√≠a Anal√≠tica\t1. Identificar gr√°ficos de funciones b√°sicas, exponenciales, logar√≠tmicas. Matem√°ticas\tMAT1610 C√°lculo I 1. Geometr√≠a Anal√≠tica\t4. Calcular derivadas de funciones obtenidas por √°lgebra de funciones elementales. Matem√°ticas\tMAT1610 C√°lculo I 1. Geometr√≠a Anal√≠tica\t6. Reconocer gr√°fica y anal√≠ticamente propiedades de los gr√°ficos de funciones, como crecimiento, concavidad, m√°ximos y m√≠nimos locales, as√≠ntotas. Matem√°ticas\tMAT1610 C√°lculo I 1. Geometr√≠a Anal√≠tica\t9. Conocer el c√°lculo de primitivas de funciones b√°sicas. Matem√°ticas\tMAT1620 C√°lculo II 1. C√°lculo Integral\t3. Aplicar el concepto de integral definida para calcular √°reas y momentos de regiones del plano. Matem√°ticas\tMAT1620 C√°lculo II 1. C√°lculo Integral\t5. Aplicar los criterios b√°sicos de convergencia de series e integrales impropias. Matem√°ticas\tMAT1620 C√°lculo II 1. C√°lculo Integral\t8. Conocer las ecuaciones param√©tricas, vectoriales y cartesianas de restas y planos en el espacio. Matem√°ticas\tMAT1630 C√°lculo III 1. C√°lculo Diferencial\t2. Aplicar el concepto de integral m√∫ltiple para evaluar vol√∫menes y centros de masa. Matem√°ticas\tMAT1630 C√°lculo III 1. C√°lculo Diferencial\t5. Reconocer y explicar el concepto de ‚Äúcurvas de nivel‚Äù y calcularlas. Matem√°ticas\tMAT1630 C√°lculo III 1. C√°lculo Diferencial\t6. Calcular derivadas direccionales. Matem√°ticas\tMAT1640 Ecuaciones Diferenciales 1. Ecuaciones Diferenciales\t2. Modelar situaciones sencillas de la realidad y de los fen√≥menos f√≠sicos b√°sicos mediante ecuaciones diferenciales. Matem√°ticas\tMAT1640 Ecuaciones Diferenciales 1. Ecuaciones Diferenciales\t3. Reconocer el tipo de una ecuaci√≥n diferencial (lineal o no, grado, orden), identificar y utilizar los distintos m√©todos disponibles para la soluci√≥n de acuerdo con el caso. Matem√°ticas\tMAT1640 Ecuaciones Diferenciales 1. Ecuaciones Diferenciales\t6. Calcular las soluciones de ecuaciones lineales y sistemas lineales de 2x2 y 3x3 de coeficientes constantes. Matem√°ticas\tMAT1203 √Ålgebra Lineal 1. Matrices 2. Raices de Ecuaciones 3. An√°lisis Vectorial\t1. Determinar la escalonada reducida de una matriz y utilizarla para estudiar la dependencia lineal de vectores, resolver un sistema Ax=b, resolver la ecuaci√≥n matricial AX=B, calcular inversas de matrices y bases de subespacios de Rn. Matem√°ticas\tMAT1203 √Ålgebra Lineal 1. Matrices 2. Raices de Ecuaciones 3. An√°lisis Vectorial\t2. Interpretar geom√©tricamente los conceptos de dependencia-independencia lineal, complemento ortogonal, sistemas de ecuaciones lineales. Matem√°ticas\tMAT1203 √Ålgebra Lineal 1. Matrices 2. Raices de Ecuaciones 3. An√°lisis Vectorial\t4. Explicar las propiedades de las operaciones matriciales y utilizarlas para simplificar y evaluar expresiones matriciales. Matem√°ticas\tMAT1203 √Ålgebra Lineal 1. Matrices 2. Raices de Ecuaciones 3. An√°lisis Vectorial\t6. Explicar y utilizar las propiedades de las matrices elementales, triangulares, sim√©tricas, sim√©tricas positivas definidas, unitarias, ortogonales. Matem√°ticas\tMAT1203 √Ålgebra Lineal 1. Matrices 2. Raices de Ecuaciones 3. An√°lisis Vectorial\t7. Explicar las propiedades de determinante y utilizarlas para calcular determinantes, resolver sistemas y evaluar inversas. Matem√°ticas\tMAT1203 √Ålgebra Lineal 1. Matrices 2. Raices de Ecuaciones 3. An√°lisis Vectorial\t9. Determinar la matriz que representa a una Transformaci√≥n Lineal entre R^n y R^m, y explicar la relaci√≥n entre cambio de base y la matriz que la representa. Matem√°ticas\tMAT1203 √Ålgebra Lineal 1. Matrices 2. Raices de Ecuaciones 3. An√°lisis Vectorial\t12. Explicar las propiedades de valores, vectores propios y ecuaci√≥n caracter√≠stica de una matriz y aplicar esto a determinar si una matriz es diagonalizable y al c√°lculo de funciones elementales de matrices. Explicar y utilizar la estructura de valores y vectores propios de matrices sim√©tricas y sus aplicaciones. Probabilidades y Estad√≠stica\tEYP1113 Probabilidades y Estad√≠stica 1. Algebra de eventos, axiomas de probabilidad, c√°lculo cl√°sico de probabilidad (conteo), probabilidad condicional, independencia, teorema de probabilidades totales y teorema de bayes. 2. Medidas descriptivas te√≥ricas de una variable aleatoria: media, moda, mediana, percentil, varianza, rango, IQR, coeficiente de variaci√≥n, coeficiente de asimetr√≠a y kurtosis. 3. Modelos usuales univariados (discretos y continuo): Binomial, Geom√©trica, Binomial Negativa, Poisson, Hipegeom√©trica, Uniforme, Normal, Log-Normal, Exponencial, Gamma, Beta, Weibull, Logistica, Log-Logistica, t-Student, chi-cuadrado y Fisher. Uso de R. 4. Distribuciones conjuntas, marginales y condicionales. Covarianza, correlaci√≥n, esperanza condicional y mejor predictor. 5. Estimaci√≥n y propiedades. M√©todos de estimaci√≥n. Uso de R. 6. Test de hip√≥tesis e intervalo de confianza. Uso de R. 7. Test de hip√≥tesis de bondad de ajuste (chi-cuadrado y ks). Uso de R. 8. Regresi√≥n lineal, coeficiente de determinaci√≥n, test-t y test-F. Uso de R.\t1. Ajustar distribuciones de probabilidades para datos que se generen en un fen√≥meno de incertidumbre. Probabilidades y Estad√≠stica\tEYP1113 Probabilidades y Estad√≠stica 1. Algebra de eventos, axiomas de probabilidad, c√°lculo cl√°sico de probabilidad (conteo), probabilidad condicional, independencia, teorema de probabilidades totales y teorema de bayes. 2. Medidas descriptivas te√≥ricas de una variable aleatoria: media, moda, mediana, percentil, varianza, rango, IQR, coeficiente de variaci√≥n, coeficiente de asimetr√≠a y kurtosis. 3. Modelos usuales univariados (discretos y continuo): Binomial, Geom√©trica, Binomial Negativa, Poisson, Hipegeom√©trica, Uniforme, Normal, Log-Normal, Exponencial, Gamma, Beta, Weibull, Logistica, Log-Logistica, t-Student, chi-cuadrado y Fisher. Uso de R. 4. Distribuciones conjuntas, marginales y condicionales. Covarianza, correlaci√≥n, esperanza condicional y mejor predictor. 5. Estimaci√≥n y propiedades. M√©todos de estimaci√≥n. Uso de R. 6. Test de hip√≥tesis e intervalo de confianza. Uso de R. 7. Test de hip√≥tesis de bondad de ajuste (chi-cuadrado y ks). Uso de R. 8. Regresi√≥n lineal, coeficiente de determinaci√≥n, test-t y test-F. Uso de R.\t2. Describir fen√≥menos de incertidumbre sobre la base de variables aleatorias y hacer c√°lculos asociados a ese fen√≥meno en base a esas variables aleatorias. Probabilidades y Estad√≠stica\tEYP1113 Probabilidades y Estad√≠stica 1. Algebra de eventos, axiomas de probabilidad, c√°lculo cl√°sico de probabilidad (conteo), probabilidad condicional, independencia, teorema de probabilidades totales y teorema de bayes. 2. Medidas descriptivas te√≥ricas de una variable aleatoria: media, moda, mediana, percentil, varianza, rango, IQR, coeficiente de variaci√≥n, coeficiente de asimetr√≠a y kurtosis. 3. Modelos usuales univariados (discretos y continuo): Binomial, Geom√©trica, Binomial Negativa, Poisson, Hipegeom√©trica, Uniforme, Normal, Log-Normal, Exponencial, Gamma, Beta, Weibull, Logistica, Log-Logistica, t-Student, chi-cuadrado y Fisher. Uso de R. 4. Distribuciones conjuntas, marginales y condicionales. Covarianza, correlaci√≥n, esperanza condicional y mejor predictor. 5. Estimaci√≥n y propiedades. M√©todos de estimaci√≥n. Uso de R. 6. Test de hip√≥tesis e intervalo de confianza. Uso de R. 7. Test de hip√≥tesis de bondad de ajuste (chi-cuadrado y ks). Uso de R. 8. Regresi√≥n lineal, coeficiente de determinaci√≥n, test-t y test-F. Uso de R.\t3. Realizar estimaciones de par√°metros de una distribuci√≥n en base a datos del fen√≥meno aleatorio y construir intervalos de confianza para esos estimadores, y entender cabalmente lo que esos intervalos de confianza representan. Probabilidades y Estad√≠stica\tEYP1113 Probabilidades y Estad√≠stica 1. Algebra de eventos, axiomas de probabilidad, c√°lculo cl√°sico de probabilidad (conteo), probabilidad condicional, independencia, teorema de probabilidades totales y teorema de bayes. 2. Medidas descriptivas te√≥ricas de una variable aleatoria: media, moda, mediana, percentil, varianza, rango, IQR, coeficiente de variaci√≥n, coeficiente de asimetr√≠a y kurtosis. 3. Modelos usuales univariados (discretos y continuo): Binomial, Geom√©trica, Binomial Negativa, Poisson, Hipegeom√©trica, Uniforme, Normal, Log-Normal, Exponencial, Gamma, Beta, Weibull, Logistica, Log-Logistica, t-Student, chi-cuadrado y Fisher. Uso de R. 4. Distribuciones conjuntas, marginales y condicionales. Covarianza, correlaci√≥n, esperanza condicional y mejor predictor. 5. Estimaci√≥n y propiedades. M√©todos de estimaci√≥n. Uso de R. 6. Test de hip√≥tesis e intervalo de confianza. Uso de R. 7. Test de hip√≥tesis de bondad de ajuste (chi-cuadrado y ks). Uso de R. 8. Regresi√≥n lineal, coeficiente de determinaci√≥n, test-t y test-F. Uso de R.\t4. Ajustar modelos de regresi√≥n lineal a fen√≥menos de incertidumbre, y lograr una adecuada comprensi√≥n del rango de validez de esos modelos y de los par√°metros de los mismos.   ","version":"Next","tagName":"h3"},{"title":"Ciencias (M2)‚Äã","type":1,"pageTitle":"Introducci√≥n","url":"/apuntes-fundamentals/docs/intro#ciencias-m2","content":" Esta prueba tiene 48 preguntas y tiene una duraci√≥n de 2 horas y 50 minutos.  T√≥pico\tCurso\tContenidos\tIndicadores a evaluar (N√∫meros corresponden al correlativo del programa de cada curso)Din√°mica*\tFIS1514 Din√°mica 1. Est√°tica: 1. Resultantes de sistemas de fuerzas 2. Sistemas de fuerzas concurrentes 3. Equilibrio de cuerpos r√≠gidos 4.Marcos 5. Centroide del √°rea 6. Momentos del area de inercia 7. Fricci√≥n 2. Din√°mica 1. Movimiento lineal (por ejemplo, fuerza, masa, aceleraci√≥n, momento) 2. Movimiento angular (por ejemplo, el par, la inercia, la aceleraci√≥n, el momento) 3. Momentos de inercia 4. Principio de Impulso y cantidad de movimiento aplicados a part√≠culas y cuerpos r√≠gidos 5. Trabajo, energ√≠a, potencia y como se aplica a part√≠culas y cuerpos r√≠gidos\t2. Establecer las ecuaciones del movimiento y equilibrio de sistemas utilizando la cinem√°tica, la leyes constitutivas, y las condiciones de equilibrio. Din√°mica*\tFIS1514 Din√°mica 1. Est√°tica: 1. Resultantes de sistemas de fuerzas 2. Sistemas de fuerzas concurrentes 3. Equilibrio de cuerpos r√≠gidos 4.Marcos 5. Centroide del √°rea 6. Momentos del area de inercia 7. Fricci√≥n 2. Din√°mica 1. Movimiento lineal (por ejemplo, fuerza, masa, aceleraci√≥n, momento) 2. Movimiento angular (por ejemplo, el par, la inercia, la aceleraci√≥n, el momento) 3. Momentos de inercia 4. Principio de Impulso y cantidad de movimiento aplicados a part√≠culas y cuerpos r√≠gidos 5. Trabajo, energ√≠a, potencia y como se aplica a part√≠culas y cuerpos r√≠gidos\t3. Resolver problemas de equilibrio est√°tico y din√°mico de sistemas. Din√°mica*\tFIS1514 Din√°mica 1. Est√°tica: 1. Resultantes de sistemas de fuerzas 2. Sistemas de fuerzas concurrentes 3. Equilibrio de cuerpos r√≠gidos 4.Marcos 5. Centroide del √°rea 6. Momentos del area de inercia 7. Fricci√≥n 2. Din√°mica 1. Movimiento lineal (por ejemplo, fuerza, masa, aceleraci√≥n, momento) 2. Movimiento angular (por ejemplo, el par, la inercia, la aceleraci√≥n, el momento) 3. Momentos de inercia 4. Principio de Impulso y cantidad de movimiento aplicados a part√≠culas y cuerpos r√≠gidos 5. Trabajo, energ√≠a, potencia y como se aplica a part√≠culas y cuerpos r√≠gidos\t4. Plantear el equilibrio de sistemas utilizando los principios de energ√≠a y trabajo virtual. Din√°mica*\tFIS1514 Din√°mica 1. Est√°tica: 1. Resultantes de sistemas de fuerzas 2. Sistemas de fuerzas concurrentes 3. Equilibrio de cuerpos r√≠gidos 4.Marcos 5. Centroide del √°rea 6. Momentos del area de inercia 7. Fricci√≥n 2. Din√°mica 1. Movimiento lineal (por ejemplo, fuerza, masa, aceleraci√≥n, momento) 2. Movimiento angular (por ejemplo, el par, la inercia, la aceleraci√≥n, el momento) 3. Momentos de inercia 4. Principio de Impulso y cantidad de movimiento aplicados a part√≠culas y cuerpos r√≠gidos 5. Trabajo, energ√≠a, potencia y como se aplica a part√≠culas y cuerpos r√≠gidos\t5. Manejar el concepto de restricciones cinem√°ticas y fuerzas de v√≠nculo. Din√°mica*\tFIS1514 Din√°mica 1. Est√°tica: 1. Resultantes de sistemas de fuerzas 2. Sistemas de fuerzas concurrentes 3. Equilibrio de cuerpos r√≠gidos 4.Marcos 5. Centroide del √°rea 6. Momentos del area de inercia 7. Fricci√≥n 2. Din√°mica 1. Movimiento lineal (por ejemplo, fuerza, masa, aceleraci√≥n, momento) 2. Movimiento angular (por ejemplo, el par, la inercia, la aceleraci√≥n, el momento) 3. Momentos de inercia 4. Principio de Impulso y cantidad de movimiento aplicados a part√≠culas y cuerpos r√≠gidos 5. Trabajo, energ√≠a, potencia y como se aplica a part√≠culas y cuerpos r√≠gidos\t6. Transformar fuerzas y desplazamientos entre distintos sistemas coordenados. Din√°mica*\tFIS1514 Din√°mica 1. Est√°tica: 1. Resultantes de sistemas de fuerzas 2. Sistemas de fuerzas concurrentes 3. Equilibrio de cuerpos r√≠gidos 4.Marcos 5. Centroide del √°rea 6. Momentos del area de inercia 7. Fricci√≥n 2. Din√°mica 1. Movimiento lineal (por ejemplo, fuerza, masa, aceleraci√≥n, momento) 2. Movimiento angular (por ejemplo, el par, la inercia, la aceleraci√≥n, el momento) 3. Momentos de inercia 4. Principio de Impulso y cantidad de movimiento aplicados a part√≠culas y cuerpos r√≠gidos 5. Trabajo, energ√≠a, potencia y como se aplica a part√≠culas y cuerpos r√≠gidos\t7. Conocer planteamientos algor√≠tmicos y num√©ricos para resolver eficientemente problemas de la mec√°nica cl√°sica. Electricidad y Magnetismo\tFIS1533 Electricidad y Magnetismo 1. Carga 2. Corriente 3. Energ√≠a 4. Voltaje y poder 5. Voltaje y trabajo 6. Fuerza entre cargas 7. Leyes de voltaje y corriente (Kirchhoff, Ohm) 8. Circuitos Equivalentes (series y paralelo) 9. Capacitancia e inductancia 10. Circuitos de corriente alterna 11. Reactancia e impedancia 12. Algebra compleja b√°sica\t1. Describir el fen√≥meno del campo el√©ctrico, la conceptualizaci√≥n de carga el√©ctrica as√≠ como la corriente el√©ctrica (Ley de Gauss). Electricidad y Magnetismo\tFIS1533 Electricidad y Magnetismo 1. Carga 2. Corriente 3. Energ√≠a 4. Voltaje y poder 5. Voltaje y trabajo 6. Fuerza entre cargas 7. Leyes de voltaje y corriente (Kirchhoff, Ohm) 8. Circuitos Equivalentes (series y paralelo) 9. Capacitancia e inductancia 10. Circuitos de corriente alterna 11. Reactancia e impedancia 12. Algebra compleja b√°sica\t2. Identificar los campos vectoriales creados a trav√©s de arreglos discretos y continuos de cargas el√©ctricas. Electricidad y Magnetismo\tFIS1533 Electricidad y Magnetismo 1. Carga 2. Corriente 3. Energ√≠a 4. Voltaje y poder 5. Voltaje y trabajo 6. Fuerza entre cargas 7. Leyes de voltaje y corriente (Kirchhoff, Ohm) 8. Circuitos Equivalentes (series y paralelo) 9. Capacitancia e inductancia 10. Circuitos de corriente alterna 11. Reactancia e impedancia 12. Algebra compleja b√°sica\t4. Calcular el potencial electroest√°tico de un sistema y explicar su relaci√≥n con dispositivos reales como el capacitor. Electricidad y Magnetismo\tFIS1533 Electricidad y Magnetismo 1. Carga 2. Corriente 3. Energ√≠a 4. Voltaje y poder 5. Voltaje y trabajo 6. Fuerza entre cargas 7. Leyes de voltaje y corriente (Kirchhoff, Ohm) 8. Circuitos Equivalentes (series y paralelo) 9. Capacitancia e inductancia 10. Circuitos de corriente alterna 11. Reactancia e impedancia 12. Algebra compleja b√°sica\t5. Explicar el principio de inducci√≥n magn√©tica y su relaci√≥n con dispositivos reales como la inductancia. Electricidad y Magnetismo\tFIS1533 Electricidad y Magnetismo 1. Carga 2. Corriente 3. Energ√≠a 4. Voltaje y poder 5. Voltaje y trabajo 6. Fuerza entre cargas 7. Leyes de voltaje y corriente (Kirchhoff, Ohm) 8. Circuitos Equivalentes (series y paralelo) 9. Capacitancia e inductancia 10. Circuitos de corriente alterna 11. Reactancia e impedancia 12. Algebra compleja b√°sica\t6. Describir un circuito de corriente continua mediante las ecuaciones que lo gobiernan y de calcular la corriente y el voltaje en cada uno de sus nodos. Electricidad y Magnetismo\tFIS1533 Electricidad y Magnetismo 1. Carga 2. Corriente 3. Energ√≠a 4. Voltaje y poder 5. Voltaje y trabajo 6. Fuerza entre cargas 7. Leyes de voltaje y corriente (Kirchhoff, Ohm) 8. Circuitos Equivalentes (series y paralelo) 9. Capacitancia e inductancia 10. Circuitos de corriente alterna 11. Reactancia e impedancia 12. Algebra compleja b√°sica\t7. Describir un circuito de corriente alterna mediante las ecuaciones que lo gobiernan y de predecir su comportamiento inicial y estacionario. Qu√≠mica**\tQIM100E Qu√≠mica para Ingenier√≠a\t1. Nomenclatura 2. Oxidaci√≥n-Reducci√≥n 3. Tabla peri√≥dica 4. Estados de la materia 5. √Åcidos y Bases 6. Ecuaciones (estequiometr√≠a) 7. Metales y No Metales 8. Equilibrio\t1.2 Manejar y aplicar la conversi√≥n de unidades (Sistema Internacional y sus prefijos). Qu√≠mica**\tQIM100E Qu√≠mica para Ingenier√≠a\t1. Nomenclatura 2. Oxidaci√≥n-Reducci√≥n 3. Tabla peri√≥dica 4. Estados de la materia 5. √Åcidos y Bases 6. Ecuaciones (estequiometr√≠a) 7. Metales y No Metales 8. Equilibrio\t3.2 Discutir c√≥mo los cambios de temperatura afectan el estado de una sustancia (s√≥lido, l√≠quido y gas). Qu√≠mica**\tQIM100E Qu√≠mica para Ingenier√≠a\t1. Nomenclatura 2. Oxidaci√≥n-Reducci√≥n 3. Tabla peri√≥dica 4. Estados de la materia 5. √Åcidos y Bases 6. Ecuaciones (estequiometr√≠a) 7. Metales y No Metales 8. Equilibrio\t3.3 Describir los diferentes tipos de enlaces presentes en materiales s√≥lidos y sus estructuras cristalinas. Qu√≠mica**\tQIM100E Qu√≠mica para Ingenier√≠a\t1. Nomenclatura 2. Oxidaci√≥n-Reducci√≥n 3. Tabla peri√≥dica 4. Estados de la materia 5. √Åcidos y Bases 6. Ecuaciones (estequiometr√≠a) 7. Metales y No Metales 8. Equilibrio\t6.1 Describir el significado de equilibrio din√°mico y diferenciar equilibrios homog√©neos y heterog√©neos. Qu√≠mica**\tQIM100E Qu√≠mica para Ingenier√≠a\t1. Nomenclatura 2. Oxidaci√≥n-Reducci√≥n 3. Tabla peri√≥dica 4. Estados de la materia 5. √Åcidos y Bases 6. Ecuaciones (estequiometr√≠a) 7. Metales y No Metales 8. Equilibrio\t6.2 Entender y relacionar cuociente de reacci√≥n (Q), concentraci√≥n de especies, y constante de equilibrio (K). Qu√≠mica**\tQIM100E Qu√≠mica para Ingenier√≠a\t1. Nomenclatura 2. Oxidaci√≥n-Reducci√≥n 3. Tabla peri√≥dica 4. Estados de la materia 5. √Åcidos y Bases 6. Ecuaciones (estequiometr√≠a) 7. Metales y No Metales 8. Equilibrio\t6.3 Explicar el significado de la constante de equilibrio, y su c√°lculo a partir de las concentraciones en el equilibrio. Qu√≠mica**\tQIM100E Qu√≠mica para Ingenier√≠a\t1. Nomenclatura 2. Oxidaci√≥n-Reducci√≥n 3. Tabla peri√≥dica 4. Estados de la materia 5. √Åcidos y Bases 6. Ecuaciones (estequiometr√≠a) 7. Metales y No Metales 8. Equilibrio\t7.1 Diferenciar conceptos de electrolitos fuertes y d√©biles. Qu√≠mica**\tQIM100E Qu√≠mica para Ingenier√≠a\t1. Nomenclatura 2. Oxidaci√≥n-Reducci√≥n 3. Tabla peri√≥dica 4. Estados de la materia 5. √Åcidos y Bases 6. Ecuaciones (estequiometr√≠a) 7. Metales y No Metales 8. Equilibrio\t7.3 Identificar las relaciones entre la concentraci√≥n de iones y el pH. Discutir las relaciones entre Ka y el grado de ionizaci√≥n de √°cido. Describir el comportamiento de √°cidos y bases fuertes y d√©biles en disoluci√≥n. Qu√≠mica**\tQIM100E Qu√≠mica para Ingenier√≠a\t1. Nomenclatura 2. Oxidaci√≥n-Reducci√≥n 3. Tabla peri√≥dica 4. Estados de la materia 5. √Åcidos y Bases 6. Ecuaciones (estequiometr√≠a) 7. Metales y No Metales 8. Equilibrio\t7.4 Calcular el pH de soluciones de √°cidos, bases y sistemas buffer. Qu√≠mica**\tQIM100E Qu√≠mica para Ingenier√≠a\t1. Nomenclatura 2. Oxidaci√≥n-Reducci√≥n 3. Tabla peri√≥dica 4. Estados de la materia 5. √Åcidos y Bases 6. Ecuaciones (estequiometr√≠a) 7. Metales y No Metales 8. Equilibrio\t9.1 Formular semi-reacciones balanceadas en masa y carga. Qu√≠mica**\tQIM100E Qu√≠mica para Ingenier√≠a\t1. Nomenclatura 2. Oxidaci√≥n-Reducci√≥n 3. Tabla peri√≥dica 4. Estados de la materia 5. √Åcidos y Bases 6. Ecuaciones (estequiometr√≠a) 7. Metales y No Metales 8. Equilibrio\t9.2 Describir los componentes de una celda electroqu√≠mica. Qu√≠mica**\tQIM100E Qu√≠mica para Ingenier√≠a\t1. Nomenclatura 2. Oxidaci√≥n-Reducci√≥n 3. Tabla peri√≥dica 4. Estados de la materia 5. √Åcidos y Bases 6. Ecuaciones (estequiometr√≠a) 7. Metales y No Metales 8. Equilibrio\t9.3 Describir el electrodo est√°ndar de hidr√≥geno. Qu√≠mica**\tQIM100E Qu√≠mica para Ingenier√≠a\t1. Nomenclatura 2. Oxidaci√≥n-Reducci√≥n 3. Tabla peri√≥dica 4. Estados de la materia 5. √Åcidos y Bases 6. Ecuaciones (estequiometr√≠a) 7. Metales y No Metales 8. Equilibrio\t9.4 Identificar las relaciones entre energ√≠a de Gibbs, potencial est√°ndar y la constante de equilibrio K. Termodin√°mica\tFIS1523 Termodin√°mica 1. Leyes termodin√°micas (por ejemplo, primera ley, segunda ley) 2. Energ√≠a, calor y trabajo 3. Disponibilidad y reversibilidad 4. Ciclos 5. Gases ideales 6. Mezcla de gases 7. Fase cambios 8. Transferencia de calor 9. Propiedades de: entalp√≠a y entrop√≠a\t1. Definir el concepto de temperatura y temperatura absoluta. Termodin√°mica\tFIS1523 Termodin√°mica 1. Leyes termodin√°micas (por ejemplo, primera ley, segunda ley) 2. Energ√≠a, calor y trabajo 3. Disponibilidad y reversibilidad 4. Ciclos 5. Gases ideales 6. Mezcla de gases 7. Fase cambios 8. Transferencia de calor 9. Propiedades de: entalp√≠a y entrop√≠a\t2. Explicar el equilibrio t√©rmico y el principio de expansi√≥n t√©rmica. Termodin√°mica\tFIS1523 Termodin√°mica 1. Leyes termodin√°micas (por ejemplo, primera ley, segunda ley) 2. Energ√≠a, calor y trabajo 3. Disponibilidad y reversibilidad 4. Ciclos 5. Gases ideales 6. Mezcla de gases 7. Fase cambios 8. Transferencia de calor 9. Propiedades de: entalp√≠a y entrop√≠a\t4. Explicar la primera ley de la termodin√°mica y aplicar la ley a ejemplos con gases ideales Termodin√°mica\tFIS1523 Termodin√°mica 1. Leyes termodin√°micas (por ejemplo, primera ley, segunda ley) 2. Energ√≠a, calor y trabajo 3. Disponibilidad y reversibilidad 4. Ciclos 5. Gases ideales 6. Mezcla de gases 7. Fase cambios 8. Transferencia de calor 9. Propiedades de: entalp√≠a y entrop√≠a\t5. Describir el concepto de entrop√≠a y de la direcci√≥n de los procesos. Termodin√°mica\tFIS1523 Termodin√°mica 1. Leyes termodin√°micas (por ejemplo, primera ley, segunda ley) 2. Energ√≠a, calor y trabajo 3. Disponibilidad y reversibilidad 4. Ciclos 5. Gases ideales 6. Mezcla de gases 7. Fase cambios 8. Transferencia de calor 9. Propiedades de: entalp√≠a y entrop√≠a\t6. Calcular la entrop√≠a, potencial termodin√°mico y eficiencia en distintos ciclos ideales y reales. Termodin√°mica\tFIS1523 Termodin√°mica 1. Leyes termodin√°micas (por ejemplo, primera ley, segunda ley) 2. Energ√≠a, calor y trabajo 3. Disponibilidad y reversibilidad 4. Ciclos 5. Gases ideales 6. Mezcla de gases 7. Fase cambios 8. Transferencia de calor 9. Propiedades de: entalp√≠a y entrop√≠a\t7. Calcular varias cantidades termodin√°micas como promedios de propiedades mec√°nicas de sistemas de gran n√∫mero de part√≠culas.   ","version":"Next","tagName":"h3"},{"title":"Ingenier√≠a (M3)‚Äã","type":1,"pageTitle":"Introducci√≥n","url":"/apuntes-fundamentals/docs/intro#ingenier√≠a-m3","content":" Esta prueba tiene 32 preguntas y tiene una duraci√≥n de 1 hora y 55 minutos.  T√≥pico\tCurso\tContenidos\tIndicadores a evaluar (N√∫meros corresponden al correlativo del programa de cada curso)Econom√≠a\tICS1513 Introducci√≥n a la Econom√≠a\tA. Flujo de caja (por ejemplo, la equivalencia, tasa de retorno) B. Costo (por ejemplo, incremental, promedio, hundido, estimaci√≥n) C. An√°lisis (por ejemplo, el punto de equilibrio, de costo-beneficio) D. La incertidumbre (por ejemplo, valor esperado y el riesgo)\t1. Entender y aplicar los conceptos b√°sicos del an√°lisis econ√≥mico y entender los problema centrales que estudia la econom√≠a, tanto a nivel micro como macro. Econom√≠a\tICS1513 Introducci√≥n a la Econom√≠a\tA. Flujo de caja (por ejemplo, la equivalencia, tasa de retorno) B. Costo (por ejemplo, incremental, promedio, hundido, estimaci√≥n) C. An√°lisis (por ejemplo, el punto de equilibrio, de costo-beneficio) D. La incertidumbre (por ejemplo, valor esperado y el riesgo)\t2. Analizar los elementos fundamentales que explican el comportamiento de los agentes, el rol de los mercados y las leyes de oferta y demanda Econom√≠a\tICS1513 Introducci√≥n a la Econom√≠a\tA. Flujo de caja (por ejemplo, la equivalencia, tasa de retorno) B. Costo (por ejemplo, incremental, promedio, hundido, estimaci√≥n) C. An√°lisis (por ejemplo, el punto de equilibrio, de costo-beneficio) D. La incertidumbre (por ejemplo, valor esperado y el riesgo)\t4. Entender y aplicar los conceptos b√°sicos de flujo de caja, tasa de descuento, valor presente y tasa interna de retorno, asociados a un proyecto y ser capaz de calcularlos y aplicarlos en un proyecto. Computaci√≥n\tIIC1103 Introducci√≥n a la Programaci√≥n 1. Terminolog√≠a (tipos de memoria, CPU, velocidades de transmisi√≥n, internet) 3. Programaci√≥n\t1. Comprender conceptos b√°sicos relativos a un programa computacional, tales como algoritmos, variables, expresiones, control de flujo, funciones, listas, strings, clases y objetos. Computaci√≥n\tIIC1103 Introducci√≥n a la Programaci√≥n 1. Terminolog√≠a (tipos de memoria, CPU, velocidades de transmisi√≥n, internet) 3. Programaci√≥n\t2. Aplicar t√©cnicas fundamentales para la resoluci√≥n de diversos problemas con ayuda del computador. Computaci√≥n\tIIC1103 Introducci√≥n a la Programaci√≥n 1. Terminolog√≠a (tipos de memoria, CPU, velocidades de transmisi√≥n, internet) 3. Programaci√≥n\t3. Aplicar el razonamiento algor√≠tmico para generar la soluci√≥n a un problema como una secuencia de pasos bien definidos, incluyendo pasos condicionales, repetici√≥n de pasos, llamadas a funciones, y recursi√≥n. Computaci√≥n\tIIC1103 Introducci√≥n a la Programaci√≥n 2. Hojas de C√°lculo: Manejo Nivel B√°sico Transversal a la formaci√≥n. √âtica\tFIL188 √âtica para Ingenieros\t1. C√≥digo de √©tica (sociedades profesionales y t√©cnicas) 2. Acuerdos y contratos 3. Legislaci√≥n y √©tica 4. Responsabilidad Profesional 5. Cuestiones de protecci√≥n p√∫blica\t1. Conocer los fundamentos y las principales corrientes √©ticas que subyacen a las decisiones morales del hombre. √âtica\tFIL188 √âtica para Ingenieros\t1. C√≥digo de √©tica (sociedades profesionales y t√©cnicas) 2. Acuerdos y contratos 3. Legislaci√≥n y √©tica 4. Responsabilidad Profesional 5. Cuestiones de protecci√≥n p√∫blica\t2. Reflexionar sobre los criterios y principios para orientar la acci√≥n en el √°mbito cient√≠fico y tecnol√≥gico. √âtica\tFIL188 √âtica para Ingenieros\t1. C√≥digo de √©tica (sociedades profesionales y t√©cnicas) 2. Acuerdos y contratos 3. Legislaci√≥n y √©tica 4. Responsabilidad Profesional 5. Cuestiones de protecci√≥n p√∫blica\t3. Aplicar los principios de la √©tica a problemas espec√≠ficos de la ciencia y la tecnolog√≠a. √âtica\tFIL188 √âtica para Ingenieros\t1. C√≥digo de √©tica (sociedades profesionales y t√©cnicas) 2. Acuerdos y contratos 3. Legislaci√≥n y √©tica 4. Responsabilidad Profesional 5. Cuestiones de protecci√≥n p√∫blica\t4. Identificar los alcances de la legislaci√≥n nacional (c√≥digo de √©tica) vigente relacionada con la pr√°ctica de la ingenier√≠a y saber c√≥mo aplicarla en el ejercicio de la profesi√≥n. ","version":"Next","tagName":"h3"},{"title":"C√°lculo III","type":0,"sectionRef":"#","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_III","content":"","keywords":"","version":"Next"},{"title":"Integrales m√∫ltiples‚Äã","type":1,"pageTitle":"C√°lculo III","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_III#integrales-m√∫ltiples","content":" La integral doble de fff sobre el rect√°ngulo RRR es  ‚à¨Rf(x,y)dA=lim‚Å°m,n‚Üí‚àû‚àëi=1m‚àëj=1nf(xi,yj)ŒîA\\iint_R f(x, y) d A=\\lim _{m, n \\rightarrow \\infty} \\sum_{i=1}^m \\sum_{j=1}^n f\\left(x_i, y_j\\right) \\Delta A‚à¨R‚Äãf(x,y)dA=m,n‚Üí‚àûlim‚Äãi=1‚àëm‚Äãj=1‚àën‚Äãf(xi‚Äã,yj‚Äã)ŒîA  si el l√≠mite existe.  Integral doble  ","version":"Next","tagName":"h2"},{"title":"Volumen‚Äã","type":1,"pageTitle":"C√°lculo III","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_III#volumen","content":" Si f(x,y)‚©æ0f(x, y) \\geqslant 0f(x,y)‚©æ0, entonces el volumen VVV del s√≥lido que est√° arriba del rect√°ngulo RRR y debajo de la superficie z=f(x,y)z=f(x, y)z=f(x,y) es  V=‚à¨Rf(x,y)dAV=\\iint_R f(x, y) d AV=‚à¨R‚Äãf(x,y)dA    ","version":"Next","tagName":"h3"},{"title":"Momentos y centros de masa‚Äã","type":1,"pageTitle":"C√°lculo III","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_III#momentos-y-centros-de-masa","content":" Los momentos de una l√°mina plana que ocupa una regi√≥n DDD y tiene densidad Œ¥(x,y)\\delta(x, y)Œ¥(x,y) es  Mx=‚à¨Dy‚ÄâŒ¥(x,y)dAMy=‚à¨Dx‚ÄâŒ¥(x,y)dAM_x=\\iint_D y \\,\\delta(x, y) d A \\qquad\\qquad M_y=\\iint_D x \\,\\delta(x, y) d AMx‚Äã=‚à¨D‚ÄãyŒ¥(x,y)dAMy‚Äã=‚à¨D‚ÄãxŒ¥(x,y)dA  donde MxM_xMx‚Äã es el momento respecto al eje xxx y MyM_yMy‚Äã es el momento respecto al eje yyy.  Con los momentos, podemos encontrar el centro de masa (xÀâ,yÀâ)(\\bar{x}, \\bar{y})(xÀâ,yÀâ‚Äã) de la l√°mina, que es  xÀâ=Mym=1m‚à¨DxœÅ(x,y)dAyÀâ=Mxm=1m‚à¨DyœÅ(x,y)dA\\bar{x}=\\frac{M_y}{m}=\\frac{1}{m} \\iint_D x \\rho(x, y) d A \\qquad\\qquad \\bar{y}=\\frac{M_x}{m}=\\frac{1}{m} \\iint_D y \\rho(x, y) d AxÀâ=mMy‚Äã‚Äã=m1‚Äã‚à¨D‚ÄãxœÅ(x,y)dAyÀâ‚Äã=mMx‚Äã‚Äã=m1‚Äã‚à¨D‚ÄãyœÅ(x,y)dA  donde la masa mmm est√° dada por  m=‚à¨DœÅ(x,y)dAm=\\iint_D \\rho(x, y) d Am=‚à¨D‚ÄãœÅ(x,y)dA  Centro de masa  ","version":"Next","tagName":"h3"},{"title":"Curvas de nivel‚Äã","type":1,"pageTitle":"C√°lculo III","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_III#curvas-de-nivel","content":" Las curvas de nivel de una funci√≥n fff de dos variables son las curvas cuyas ecuaciones son f(x,y)=kf(x, y)=kf(x,y)=k, donde kkk es una constante en el rango de fff.  Curvas de nivel  ","version":"Next","tagName":"h2"},{"title":"Derivadas direccionales‚Äã","type":1,"pageTitle":"C√°lculo III","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_III#derivadas-direccionales","content":" ","version":"Next","tagName":"h2"},{"title":"Definici√≥n‚Äã","type":1,"pageTitle":"C√°lculo III","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_III#definici√≥n","content":" La derivada direccional de fff en (x0,y0)\\left(x_0, y_0\\right)(x0‚Äã,y0‚Äã) en la direcci√≥n de un vector unitario u=‚ü®a,b‚ü©\\mathbf{u}=\\langle a, b\\rangleu=‚ü®a,b‚ü© es  Duf(x0,y0)=lim‚Å°h‚Üí0f(x0+ha,y0+hb)‚àíf(x0,y0)hD_{\\mathbf{u}} f\\left(x_0, y_0\\right)=\\lim _{h \\rightarrow 0} \\frac{f\\left(x_0+h a, y_0+h b\\right)-f\\left(x_0, y_0\\right)}{h}Du‚Äãf(x0‚Äã,y0‚Äã)=h‚Üí0lim‚Äãhf(x0‚Äã+ha,y0‚Äã+hb)‚àíf(x0‚Äã,y0‚Äã)‚Äã  si este l√≠mite existe.  Derivada direccional  Si fff es una funci√≥n derivable de xxx y de yyy, entonces fff tiene una derivada direccional en la direcci√≥n de cualquier vector unitario u=‚ü®a,b‚ü©\\mathbf{u}=\\langle a, b\\rangleu=‚ü®a,b‚ü© y  Duf(x,y)=fx(x,y)a+fy(x,y)bD_{\\mathrm{u}} f(x, y)=f_x(x, y) a+f_y(x, y) bDu‚Äãf(x,y)=fx‚Äã(x,y)a+fy‚Äã(x,y)b  ","version":"Next","tagName":"h2"},{"title":"Gradiente‚Äã","type":1,"pageTitle":"C√°lculo III","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_III#gradiente","content":" Si fff es una funci√≥n de dos variables xxx y yyy, entonces el gradiente de fff es la funci√≥n vectorial ‚àáf\\nabla f‚àáf definida por  ‚àáf(x,y)=‚ü®fx(x,y),fy(x,y)‚ü©=‚àÇf‚àÇxi+‚àÇf‚àÇyj\\nabla f(x, y)=\\left\\langle f_x(x, y), f_y(x, y)\\right\\rangle=\\frac{\\partial f}{\\partial x} \\mathbf{i}+\\frac{\\partial f}{\\partial y} \\mathbf{j}‚àáf(x,y)=‚ü®fx‚Äã(x,y),fy‚Äã(x,y)‚ü©=‚àÇx‚àÇf‚Äãi+‚àÇy‚àÇf‚Äãj  Con esta notaci√≥n para el vector gradiente, podemos escribir la expresi√≥n para la derivada direccional como  Duf(x,y)=‚àáf(x,y)‚ãÖuD_{\\mathbf{u}} f(x, y)=\\nabla f(x, y) \\cdot \\mathbf{u}Du‚Äãf(x,y)=‚àáf(x,y)‚ãÖu  ","version":"Next","tagName":"h3"},{"title":"M√°ximo de la derivada direccional‚Äã","type":1,"pageTitle":"C√°lculo III","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_III#m√°ximo-de-la-derivada-direccional","content":" Supongamos que fff es una funci√≥n derivable de dos o tres variables. El valor m√°ximo de la derivada direccional Duf(x)D_{\\mathbf{u}} f(\\mathbf{x})Du‚Äãf(x) es ‚à£‚àáf(x)‚à£|\\nabla f(\\mathbf{x})|‚à£‚àáf(x)‚à£ y se presenta cuando u\\mathbf{u}u tiene la misma direcci√≥n que el vector gradiente ‚àáf(x)\\nabla f(\\mathbf{x})‚àáf(x). ","version":"Next","tagName":"h3"},{"title":"C√°lculo I","type":0,"sectionRef":"#","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_I","content":"","keywords":"","version":"Next"},{"title":"Gr√°ficos de funciones‚Äã","type":1,"pageTitle":"C√°lculo I","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_I#gr√°ficos-de-funciones","content":" Los gr√°ficos de funciones b√°sicas, exponenciales y logar√≠tmicas son:    ","version":"Next","tagName":"h2"},{"title":"Derivadas‚Äã","type":1,"pageTitle":"C√°lculo I","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_I#derivadas","content":" La derivada de una funci√≥n fff en un n√∫mero x=ax = ax=a, denotada por f‚Ä≤(a)f'(a)f‚Ä≤(a), es  f‚Ä≤(a)=lim‚Å°h‚Üí0f(a+h)‚àíf(a)hf^{\\prime}(a) = \\lim _{h \\rightarrow 0} \\frac{f(a+h)-f(a)}{h}f‚Ä≤(a)=h‚Üí0lim‚Äãhf(a+h)‚àíf(a)‚Äã  si este l√≠mite existe.  A continuaci√≥n se presentan las derivadas de las funciones m√°s comunes:  Funci√≥n\tDerivada\tDerivada con regla de la cadenaPotencia\tddx[xn]=nxn‚àí1\\frac{d}{d x}\\left[x^n\\right]=n x^{n-1}dxd‚Äã[xn]=nxn‚àí1\tddx[un]=nun‚àí1‚ãÖu‚Ä≤\\frac{d}{d x}\\left[u^n\\right]=n u^{n-1} \\cdot u^{\\prime}dxd‚Äã[un]=nun‚àí1‚ãÖu‚Ä≤ Exponencial (base eee)\tddx[ex]=ex\\frac{d}{d x}\\left[e^x\\right]=e^xdxd‚Äã[ex]=ex\tddx[eu]=eu‚ãÖu‚Ä≤\\frac{d}{d x}\\left[e^u\\right]=e^u \\cdot u^{\\prime}dxd‚Äã[eu]=eu‚ãÖu‚Ä≤ Exponencial (base aaa)\tddx[ax]=axln‚Å°(a)\\frac{d}{d x}\\left[a^x\\right]=a^x \\ln (a)dxd‚Äã[ax]=axln(a)\tddx[au]=auln‚Å°(a)‚ãÖu‚Ä≤\\frac{d}{d x}\\left[a^u\\right]=a^u \\ln (a) \\cdot u^{\\prime}dxd‚Äã[au]=auln(a)‚ãÖu‚Ä≤ Logaritmo Natural\tddx[ln‚Å°(x)]=1x\\frac{d}{d x}[\\ln (x)]=\\frac{1}{x}dxd‚Äã[ln(x)]=x1‚Äã\tddx[ln‚Å°(u)]=1u‚ãÖu‚Ä≤\\frac{d}{d x}[\\ln (u)]=\\frac{1}{u} \\cdot u^{\\prime}dxd‚Äã[ln(u)]=u1‚Äã‚ãÖu‚Ä≤ o u‚Ä≤u\\frac{u^{\\prime}}{u}uu‚Ä≤‚Äã Logaritmo (base aaa)\tddx[log‚Å°a(x)]=1x‚ãÖln‚Å°(a)\\frac{d}{d x}\\left[\\log _a(x)\\right]=\\frac{1}{x \\cdot \\ln (a)}dxd‚Äã[loga‚Äã(x)]=x‚ãÖln(a)1‚Äã\tddx[log‚Å°a(u)]=1u‚ãÖln‚Å°(a)‚ãÖu‚Ä≤\\frac{d}{d x}\\left[\\log _a(u)\\right]=\\frac{1}{u \\cdot \\ln (a)} \\cdot u^{\\prime}dxd‚Äã[loga‚Äã(u)]=u‚ãÖln(a)1‚Äã‚ãÖu‚Ä≤ Seno\tddx[sin‚Å°(x)]=cos‚Å°(x)\\frac{d}{d x}[\\sin (x)]=\\cos (x)dxd‚Äã[sin(x)]=cos(x)\tddx[sin‚Å°u]=cos‚Å°(u)‚ãÖu‚Ä≤\\frac{d}{d x}[\\sin u]=\\cos (u) \\cdot u^{\\prime}dxd‚Äã[sinu]=cos(u)‚ãÖu‚Ä≤ Coseno\tddx[cos‚Å°(x)]=‚àísin‚Å°(x)\\frac{d}{d x}[\\cos (x)]=-\\sin (x)dxd‚Äã[cos(x)]=‚àísin(x)\tddx[cos‚Å°u]=‚àísin‚Å°(u)‚ãÖu‚Ä≤\\frac{d}{d x}[\\cos u]=-\\sin (u) \\cdot u^{\\prime}dxd‚Äã[cosu]=‚àísin(u)‚ãÖu‚Ä≤ Tangente\tddx[tan‚Å°(x)]=sec‚Å°2(x)\\frac{d}{d x}[\\tan (x)]=\\sec ^2(x)dxd‚Äã[tan(x)]=sec2(x)\tddx[tan‚Å°(u)]=sec‚Å°2(u)‚ãÖu‚Ä≤\\frac{d}{d x}[\\tan (u)]=\\sec ^2(u) \\cdot u^{\\prime}dxd‚Äã[tan(u)]=sec2(u)‚ãÖu‚Ä≤ Cosecante\tddx[csc‚Å°(x)]=‚àícsc‚Å°(x)cot‚Å°(x)\\frac{d}{d x}[\\csc (x)]=-\\csc (x) \\cot (x)dxd‚Äã[csc(x)]=‚àícsc(x)cot(x)\tddx[csc‚Å°(u)]=‚àícsc‚Å°(u)cot‚Å°(u)‚ãÖu‚Ä≤\\frac{d}{d x}[\\csc (u)]=-\\csc (u) \\cot (u) \\cdot u^{\\prime}dxd‚Äã[csc(u)]=‚àícsc(u)cot(u)‚ãÖu‚Ä≤ Secante\tddx[sec‚Å°(x)]=sec‚Å°(x)tan‚Å°(x)\\frac{d}{d x}[\\sec (x)]=\\sec (x) \\tan (x)dxd‚Äã[sec(x)]=sec(x)tan(x)\tddx[sec‚Å°(u)]=sec‚Å°(u)tan‚Å°(u)‚ãÖu‚Ä≤\\frac{d}{d x}[\\sec (u)]=\\sec (u) \\tan (u) \\cdot u^{\\prime}dxd‚Äã[sec(u)]=sec(u)tan(u)‚ãÖu‚Ä≤ Cotangente\tddx[cot‚Å°(x)]=‚àícsc‚Å°2(x)\\frac{d}{d x}[\\cot (x)]=-\\csc ^2(x)dxd‚Äã[cot(x)]=‚àícsc2(x)\tddx[cot‚Å°(u)]=‚àícsc‚Å°2(u)‚ãÖu‚Ä≤\\frac{d}{d x}[\\cot (u)]=-\\csc ^2(u) \\cdot u^{\\prime}dxd‚Äã[cot(u)]=‚àícsc2(u)‚ãÖu‚Ä≤ Arcoseno\tddxsin‚Å°‚àí1(x)=11‚àíx2\\frac{d}{d x} \\sin ^{-1}(x)=\\frac{1}{\\sqrt{1-x^2}}dxd‚Äãsin‚àí1(x)=1‚àíx2‚Äã1‚Äã\tddxsin‚Å°‚àí1(u)=11‚àíu2‚ãÖu‚Ä≤\\frac{d}{d x} \\sin ^{-1}(u)=\\frac{1}{\\sqrt{1-u^2}} \\cdot u^{\\prime}dxd‚Äãsin‚àí1(u)=1‚àíu2‚Äã1‚Äã‚ãÖu‚Ä≤ Arcocoseno\tddxcos‚Å°‚àí1(x)=‚àí11‚àíx2\\frac{d}{d x} \\cos ^{-1}(x)=\\frac{-1}{\\sqrt{1-x^2}}dxd‚Äãcos‚àí1(x)=1‚àíx2‚Äã‚àí1‚Äã\tddxcos‚Å°‚àí1(u)=‚àí11‚àíu2‚ãÖu‚Ä≤\\frac{d}{d x} \\cos ^{-1}(u)=\\frac{-1}{\\sqrt{1-u^2}} \\cdot u^{\\prime}dxd‚Äãcos‚àí1(u)=1‚àíu2‚Äã‚àí1‚Äã‚ãÖu‚Ä≤ Arcotangente\tddxtan‚Å°‚àí1(x)=11+x2\\frac{d}{d x} \\tan ^{-1}(x)=\\frac{1}{1+x^2}dxd‚Äãtan‚àí1(x)=1+x21‚Äã\tddxtan‚Å°‚àí1(u)=11+u2‚ãÖu‚Ä≤\\frac{d}{d x} \\tan ^{-1}(u)=\\frac{1}{1+u^2} \\cdot u^{\\prime}dxd‚Äãtan‚àí1(u)=1+u21‚Äã‚ãÖu‚Ä≤ Arcocosecante\tddxcsc‚Å°‚àí1(x)=‚àí1‚à•x‚à•x2‚àí1\\frac{d}{d x} \\csc ^{-1}(x)=\\frac{-1}{\\|x\\| \\sqrt{x^2-1}}dxd‚Äãcsc‚àí1(x)=‚à•x‚à•x2‚àí1‚Äã‚àí1‚Äã\tddxcsc‚Å°‚àí1(u)=‚àí1‚à•u‚à•u2‚àí1‚ãÖu‚Ä≤\\frac{d}{d x} \\csc ^{-1}(u)=\\frac{-1}{\\|u\\| \\sqrt{u^2-1}} \\cdot u^{\\prime}dxd‚Äãcsc‚àí1(u)=‚à•u‚à•u2‚àí1‚Äã‚àí1‚Äã‚ãÖu‚Ä≤ Arcosecante\tddxsec‚Å°‚àí1(x)=1‚à•x‚à•x2‚àí1\\frac{d}{d x} \\sec ^{-1}(x)=\\frac{1}{\\|x\\| \\sqrt{x^2-1}}dxd‚Äãsec‚àí1(x)=‚à•x‚à•x2‚àí1‚Äã1‚Äã\tddxsec‚Å°‚àí1(u)=1‚à•u‚à•u2‚àí1‚ãÖu‚Ä≤\\frac{d}{d x} \\sec ^{-1}(u)=\\frac{1}{\\|u\\| \\sqrt{u^2-1}} \\cdot u^{\\prime}dxd‚Äãsec‚àí1(u)=‚à•u‚à•u2‚àí1‚Äã1‚Äã‚ãÖu‚Ä≤ Arcocotangente\tddxcot‚Å°‚àí1(x)=‚àí11+x2\\frac{d}{d x} \\cot ^{-1}(x)=\\frac{-1}{1+x^2}dxd‚Äãcot‚àí1(x)=1+x2‚àí1‚Äã\tddxcot‚Å°‚àí1(u)=‚àí11+u2‚ãÖu‚Ä≤\\frac{d}{d x} \\cot ^{-1}(u)=\\frac{-1}{1+u^2} \\cdot u^{\\prime}dxd‚Äãcot‚àí1(u)=1+u2‚àí1‚Äã‚ãÖu‚Ä≤  ","version":"Next","tagName":"h2"},{"title":"Propiedades anal√≠ticas de los gr√°ficos‚Äã","type":1,"pageTitle":"C√°lculo I","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_I#propiedades-anal√≠ticas-de-los-gr√°ficos","content":" ","version":"Next","tagName":"h2"},{"title":"M√°ximos y m√≠nimos‚Äã","type":1,"pageTitle":"C√°lculo I","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_I#m√°ximos-y-m√≠nimos","content":" Sea ccc un n√∫mero en el dominio DDD de una funci√≥n fff. Entonces f(c)f(c)f(c) es el:  valor m√°ximo absoluto de fff sobre DDD si f(c)‚©æf(x)f(c) \\geqslant f(x)f(c)‚©æf(x) para toda xxx en DDD.valor m√≠nimo absoluto de fff sobre DDD si f(c)‚©Ωf(x)f(c) \\leqslant f(x)f(c)‚©Ωf(x) para toda xxx en DDD.  El n√∫mero f(c)f(c)f(c) es un:  valor m√°ximo local de fff si f(c)‚©æf(x)f(c) \\geqslant f(x)f(c)‚©æf(x) cuando xxx est√° cerca de ccc.valor m√≠nimo local de fff si f(c)‚©Ωf(x)f(c) \\leqslant f(x)f(c)‚©Ωf(x) cuando xxx est√° cerca de ccc.    ","version":"Next","tagName":"h3"},{"title":"Teorema del valor extremo‚Äã","type":1,"pageTitle":"C√°lculo I","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_I#teorema-del-valor-extremo","content":" Si fff es continua solve un intervalo cerrado [a,b][a, b][a,b], entonces fff alcanza un valor m√°ximo absoluto f(c)f(c)f(c) y un valor minimo absoluto f(d)f(d)f(d) en algunos n√∫meros ccc y ddd en [a,b][a, b][a,b].  Teorema del valor extremo  ","version":"Next","tagName":"h3"},{"title":"Teorema de Fermat‚Äã","type":1,"pageTitle":"C√°lculo I","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_I#teorema-de-fermat","content":" Si fff tiene un valor m√°ximo o m√≠nimo local en ccc, y si f‚Ä≤(c)f'(c)f‚Ä≤(c) existe, entonces f‚Ä≤(c)=0f'(c) = 0f‚Ä≤(c)=0.  Teorema de Fermat  ","version":"Next","tagName":"h3"},{"title":"N√∫meros cr√≠ticos‚Äã","type":1,"pageTitle":"C√°lculo I","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_I#n√∫meros-cr√≠ticos","content":" Un n√∫mero cr√≠tico de una funci√≥n fff es un n√∫mero ccc en el dominio de fff tal que f‚Ä≤(c)=0f'(c) = 0f‚Ä≤(c)=0 o f‚Ä≤(c)f'(c)f‚Ä≤(c) no existe.    ","version":"Next","tagName":"h3"},{"title":"M√©todo del intervalo cerrado‚Äã","type":1,"pageTitle":"C√°lculo I","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_I#m√©todo-del-intervalo-cerrado","content":" Para hallar los valores m√°ximo y m√≠nimo absolutos de una funci√≥n continua fff sobre un intervalo cerrado [a,b][a, b][a,b]:  Encuentre los valores de fff en los n√∫meros cr√≠ticos de fff en (a,b)(a, b)(a,b).Halle los valores de fff en los puntos extremos del intervalo.El m√°s grande de los valores de los pasos 1 y 2 es el valor m√°ximo absoluto; el m√°s peque√±o, el valor m√≠nimo absoluto.  Ejemplo de m√©todo del intervalo cerrado  ","version":"Next","tagName":"h3"},{"title":"Teorema del valor medio‚Äã","type":1,"pageTitle":"C√°lculo I","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_I#teorema-del-valor-medio","content":" Si fff es una funci√≥n que satisface las siguientes hip√≥tesis:  fff es continua sobre el intervalo cerrado [a,b][a, b][a,b]fff es derivable sobre el intervalo abierto (a,b)(a, b)(a,b) entonces existe un n√∫mero x=cx=cx=c en (a,b)(a, b)(a,b) tal que  f‚Ä≤(c)=f(b)‚àíf(a)b‚àíaf^{\\prime}(c)=\\frac{f(b)-f(a)}{b-a}f‚Ä≤(c)=b‚àíaf(b)‚àíf(a)‚Äã  o, equivalentemente,  f(b)‚àíf(a)=f‚Ä≤(c)(b‚àía)f(b)-f(a)=f^{\\prime}(c)(b-a)f(b)‚àíf(a)=f‚Ä≤(c)(b‚àía)  Teorema del valor medio  ","version":"Next","tagName":"h3"},{"title":"Prueba de crecimiento y decrecimiento‚Äã","type":1,"pageTitle":"C√°lculo I","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_I#prueba-de-crecimiento-y-decrecimiento","content":" Si f‚Ä≤(x)&gt;0f'(x) &gt; 0f‚Ä≤(x)&gt;0 para todo xxx en un intervalo, entonces fff es creciente en ese intervalo.Si f‚Ä≤(x)&lt;0f'(x) &lt; 0f‚Ä≤(x)&lt;0 para todo xxx en un intervalo, entonces fff es decreciente en ese intervalo.  Prueba creciente/decreciente  ","version":"Next","tagName":"h3"},{"title":"Prueba de concavidad‚Äã","type":1,"pageTitle":"C√°lculo I","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_I#prueba-de-concavidad","content":" Si f‚Ä≤‚Ä≤(x)&gt;0f''(x) &gt; 0f‚Ä≤‚Ä≤(x)&gt;0 para todo xxx en un intervalo, entonces fff es c√≥ncava hacia arriba en ese intervalo.Si f‚Ä≤‚Ä≤(x)&lt;0f''(x) &lt; 0f‚Ä≤‚Ä≤(x)&lt;0 para todo xxx en un intervalo, entonces fff es c√≥ncava hacia abajo en ese intervalo.    ","version":"Next","tagName":"h3"},{"title":"As√≠ntotas‚Äã","type":1,"pageTitle":"C√°lculo I","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_I#as√≠ntotas","content":" La recta x=ax=ax=a se llama as√≠ntota vertical de la curva y=f(x)y=f(x)y=f(x) si al menos una de las siguientes afirmaciones son verdaderas:  lim‚Å°x‚Üíaf(x)=‚àûlim‚Å°x‚Üía‚àíf(x)=‚àûlim‚Å°x‚Üía+f(x)=‚àûlim‚Å°x‚Üíaf(x)=‚àí‚àûlim‚Å°x‚Üía‚àíf(x)=‚àí‚àûlim‚Å°x‚Üía+f(x)=‚àí‚àû\\begin{array}{lll} \\displaystyle{\\lim _{x \\rightarrow a} f(x)=\\infty} &amp; \\displaystyle{\\lim _{x \\rightarrow a^{-}} f(x)=\\infty} &amp; \\displaystyle{\\lim _{x \\rightarrow a^{+}} f(x)=\\infty} \\\\[20pt] \\displaystyle{\\lim _{x \\rightarrow a} f(x)=-\\infty} &amp; \\displaystyle{\\lim _{x \\rightarrow a^{-}} f(x)=-\\infty} &amp; \\displaystyle{\\lim _{x \\rightarrow a^{+}} f(x)=-\\infty} \\end{array}x‚Üíalim‚Äãf(x)=‚àûx‚Üíalim‚Äãf(x)=‚àí‚àû‚Äãx‚Üía‚àílim‚Äãf(x)=‚àûx‚Üía‚àílim‚Äãf(x)=‚àí‚àû‚Äãx‚Üía+lim‚Äãf(x)=‚àûx‚Üía+lim‚Äãf(x)=‚àí‚àû‚Äã  As√≠ntotas verticales  La recta y=Ly=Ly=L se llama as√≠ntota horizontal de la curva y=f(x)y=f(x)y=f(x) si  lim‚Å°x‚Üí‚àûf(x)=L¬†o¬†lim‚Å°x‚Üí‚àí‚àûf(x)=L\\lim _{x \\rightarrow \\infty} f(x)=L \\quad \\text { o } \\quad \\lim _{x \\rightarrow-\\infty} f(x)=Lx‚Üí‚àûlim‚Äãf(x)=L¬†o¬†x‚Üí‚àí‚àûlim‚Äãf(x)=L  As√≠ntotas horizontales  Algunas curvas tienen as√≠ntotas que son oblicuas; esto es, no son horizontales ni verticales. Si  lim‚Å°x‚Üí‚àû[f(x)‚àí(mx+b)]=0\\lim _{x \\rightarrow \\infty}[f(x)-(m x+b)]=0x‚Üí‚àûlim‚Äã[f(x)‚àí(mx+b)]=0  entonces la recta y=mx+by=m x+by=mx+b se llama as√≠ntota inclinada (oblicua).  As√≠ntotas oblicuas ","version":"Next","tagName":"h3"},{"title":"C√°lculo II","type":0,"sectionRef":"#","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_II","content":"","keywords":"","version":"Next"},{"title":"Integral definida‚Äã","type":1,"pageTitle":"C√°lculo II","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_II#integral-definida","content":" El √°rea AAA de la regi√≥n SSS que se encuentra bajo la gr√°fica de la funci√≥n continua fff es el l√≠mite de la suma de las √°reas de los rect√°ngulos de aproximaci√≥n:  A=lim‚Å°n‚Üí‚àûRn=lim‚Å°n‚Üí‚àû[f(x1)Œîx+f(x2)Œîx+‚ãØ+f(xn)Œîx]A=\\lim _{n \\rightarrow \\infty} R_n=\\lim _{n \\rightarrow \\infty}\\left[f\\left(x_1\\right) \\Delta x+f\\left(x_2\\right) \\Delta x+\\cdots+f\\left(x_n\\right) \\Delta x\\right]A=n‚Üí‚àûlim‚ÄãRn‚Äã=n‚Üí‚àûlim‚Äã[f(x1‚Äã)Œîx+f(x2‚Äã)Œîx+‚ãØ+f(xn‚Äã)Œîx]  Suma de Riemman  Si fff es una funci√≥n continua definida para a‚©Ωx‚©Ωba \\leqslant x \\leqslant ba‚©Ωx‚©Ωb, dividimos el intervalo [a,b][a, b][a,b] en nnn subintervalos de igual ancho Œîx=(b‚àía)/n\\Delta x=(b-a) / nŒîx=(b‚àía)/n. Sean x0(=a),x1,x2,‚Ä¶,xn(=b)x_0(=a), x_1, x_2, \\ldots, x_n(=b)x0‚Äã(=a),x1‚Äã,x2‚Äã,‚Ä¶,xn‚Äã(=b) los puntos extremos de estos subintervalos y sean x1‚àó,x2‚àó,‚Ä¶,xn‚àóx_1^*, x_2^*, \\ldots, x_n^*x1‚àó‚Äã,x2‚àó‚Äã,‚Ä¶,xn‚àó‚Äã los puntos muestra en estos subintervalos, de modo que xi‚àóx_i^*xi‚àó‚Äã se encuentre en el iii-√©simo subintervalo [xi‚àí1,xi]\\left[x_{i-1}, x_i\\right][xi‚àí1‚Äã,xi‚Äã]. Entonces la integral definida de fff, desde aaa hasta bbb, es  ‚à´abf(x)dx=lim‚Å°n‚Üí‚àû‚àëi=1nf(xi‚àó)Œîx\\int_a^b f(x) d x=\\lim _{n \\rightarrow \\infty} \\sum_{i=1}^n f\\left(x_i^*\\right) \\Delta x‚à´ab‚Äãf(x)dx=n‚Üí‚àûlim‚Äãi=1‚àën‚Äãf(xi‚àó‚Äã)Œîx  siempre que este l√≠mite exista y d√© el mismo valor para todos las posibles elecciones de los puntos muestra. Si existe, decimos que fff es integrable sobre [a,b][a, b][a,b].  Integral definida  ","version":"Next","tagName":"h2"},{"title":"Propiedades de la integral definida‚Äã","type":1,"pageTitle":"C√°lculo II","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_II#propiedades-de-la-integral-definida","content":" Cuando se defini√≥ la integral definida ‚à´abf(x)dx\\int_a^b f(x) d x‚à´ab‚Äãf(x)dx, de manera impl√≠cita se supuso que a&lt;ba&lt;ba&lt;b. Pero la definici√≥n como un l√≠mite de la suma de Riemann tiene sentido aun cuando a&gt;ba&gt;ba&gt;b. Note que si invertimos aaa y bbb, entonces Œîx\\Delta xŒîx cambia de (b‚àía)/n(b-a) / n(b‚àía)/n a (a‚àíb)/n(a-b) / n(a‚àíb)/n. En consecuencia,  ‚à´baf(x)dx=‚àí‚à´abf(x)dx\\int_b^a f(x) d x=-\\int_a^b f(x) d x‚à´ba‚Äãf(x)dx=‚àí‚à´ab‚Äãf(x)dx  Si a=ba=ba=b, entonces Œîx=0\\Delta x=0Œîx=0 de manera que  ‚à´aaf(x)dx=0\\int_a^a f(x) d x=0‚à´aa‚Äãf(x)dx=0  Otras propiedades:  ‚à´abcdx=c(b‚àía)\\displaystyle\\int_a^b c d x=c(b-a)‚à´ab‚Äãcdx=c(b‚àía), donde ccc es cualquier constante‚à´ab[f(x)+g(x)]dx=‚à´abf(x)dx+‚à´abg(x)dx\\displaystyle\\int_a^b[f(x)+g(x)] d x=\\int_a^b f(x) d x+\\int_a^b g(x) d x‚à´ab‚Äã[f(x)+g(x)]dx=‚à´ab‚Äãf(x)dx+‚à´ab‚Äãg(x)dx‚à´abcf(x)dx=c‚à´abf(x)dx\\displaystyle\\int_a^b c f(x) d x=c \\int_a^b f(x) d x‚à´ab‚Äãcf(x)dx=c‚à´ab‚Äãf(x)dx, donde ccc es cualquier constante‚à´ab[f(x)‚àíg(x)]dx=‚à´abf(x)dx‚àí‚à´abg(x)dx\\displaystyle\\int_a^b[f(x)-g(x)] d x=\\int_a^b f(x) d x-\\int_a^b g(x) d x‚à´ab‚Äã[f(x)‚àíg(x)]dx=‚à´ab‚Äãf(x)dx‚àí‚à´ab‚Äãg(x)dx‚à´acf(x)dx+‚à´cbf(x)dx=‚à´abf(x)dx\\displaystyle\\int_a^c f(x) d x+\\int_c^b f(x) d x=\\int_a^b f(x) d x‚à´ac‚Äãf(x)dx+‚à´cb‚Äãf(x)dx=‚à´ab‚Äãf(x)dx  ","version":"Next","tagName":"h3"},{"title":"Teorema fundamental del c√°lculo‚Äã","type":1,"pageTitle":"C√°lculo II","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_II#teorema-fundamental-del-c√°lculo","content":" Suponga que fff es continua sobre [a,b][a, b][a,b].  Si g(x)=‚à´axf(t)dt\\displaystyle g(x)=\\int_a^x f(t) d tg(x)=‚à´ax‚Äãf(t)dt, entonces g‚Ä≤(x)=f(x)g^{\\prime}(x)=f(x)g‚Ä≤(x)=f(x).‚à´abf(x)dx=F(b)‚àíF(a)\\displaystyle \\int_a^b f(x) d x=F(b)-F(a)‚à´ab‚Äãf(x)dx=F(b)‚àíF(a), donde FFF es cualquier antiderivada de fff; es decir, F‚Ä≤=fF^{\\prime}=fF‚Ä≤=f.  ","version":"Next","tagName":"h2"},{"title":"Criterios de convergencia‚Äã","type":1,"pageTitle":"C√°lculo II","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_II#criterios-de-convergencia","content":" Para series, la siguiente tabla resume los criterios de convergencia:  Criterio\tCuando usar\tConclusi√≥nSerie geom√©trica\t‚àën=0‚àûarn\\displaystyle \\sum_{n=0}^{\\infty} a r^nn=0‚àë‚àû‚Äãarn\tConverge si ‚à£r‚à£&lt;1\\lvert r \\rvert&lt;1‚à£r‚à£&lt;1, diverge si ‚à£r‚à£‚â•1\\lvert r \\rvert \\geq 1‚à£r‚à£‚â•1 Test de la divergencia\tCualquier serie ‚àën=1‚àûan\\displaystyle \\sum_{n=1}^{\\infty} a_nn=1‚àë‚àû‚Äãan‚Äã\tSi lim‚Å°n‚Üí‚àûan‚â†0\\displaystyle \\lim_{n \\to \\infty} a_n \\neq 0n‚Üí‚àûlim‚Äãan‚ÄãÓÄ†=0, entonces la serie diverge Serie ppp\t‚àën=1‚àû1np\\displaystyle \\sum_{n=1}^{\\infty} \\frac{1}{n^p}n=1‚àë‚àû‚Äãnp1‚Äã\tConverge si p&gt;1p&gt;1p&gt;1, diverge si p‚â§1p \\leq 1p‚â§1 Test de comparaci√≥n\t‚àën=1‚àûan\\displaystyle \\sum_{n=1}^{\\infty} a_nn=1‚àë‚àû‚Äãan‚Äã y ‚àën=1‚àûbn\\displaystyle \\sum_{n=1}^{\\infty} b_nn=1‚àë‚àû‚Äãbn‚Äã, con 0‚â§an‚â§bn0 \\leq a_n \\leq b_n0‚â§an‚Äã‚â§bn‚Äã\tSi ‚àën=1‚àûbn\\displaystyle \\sum_{n=1}^{\\infty} b_nn=1‚àë‚àû‚Äãbn‚Äã converge, entonces ‚àën=1‚àûan\\displaystyle \\sum_{n=1}^{\\infty} a_nn=1‚àë‚àû‚Äãan‚Äã converge Si ‚àën=1‚àûan\\displaystyle \\sum_{n=1}^{\\infty} a_nn=1‚àë‚àû‚Äãan‚Äã diverge, entonces ‚àën=1‚àûbn\\displaystyle \\sum_{n=1}^{\\infty} b_nn=1‚àë‚àû‚Äãbn‚Äã diverge Test de comparaci√≥n en el l√≠mite\t‚àën=1‚àûan\\displaystyle \\sum_{n=1}^{\\infty} a_nn=1‚àë‚àû‚Äãan‚Äã y ‚àën=1‚àûbn\\displaystyle \\sum_{n=1}^{\\infty} b_nn=1‚àë‚àû‚Äãbn‚Äã, con an,bn&gt;0a_n, b_n &gt; 0an‚Äã,bn‚Äã&gt;0\tSi lim‚Å°n‚Üí‚àûanbn=c\\displaystyle \\lim_{n \\to \\infty} \\frac{a_n}{b_n}=cn‚Üí‚àûlim‚Äãbn‚Äãan‚Äã‚Äã=c, donde ccc es una constante positiva, entonces ‚àën=1‚àûan\\displaystyle \\sum_{n=1}^{\\infty} a_nn=1‚àë‚àû‚Äãan‚Äã y ‚àën=1‚àûbn\\displaystyle \\sum_{n=1}^{\\infty} b_nn=1‚àë‚àû‚Äãbn‚Äã convergen o divergen juntas Serie alternante\t‚àën=1‚àû(‚àí1)n‚àí1an\\displaystyle \\sum_{n=1}^{\\infty} (-1)^{n-1} a_nn=1‚àë‚àû‚Äã(‚àí1)n‚àí1an‚Äã o ‚àën=1‚àû(‚àí1)nan\\displaystyle \\sum_{n=1}^{\\infty} (-1)^n a_nn=1‚àë‚àû‚Äã(‚àí1)nan‚Äã, con an&gt;0a_n &gt; 0an‚Äã&gt;0\tConverge si lim‚Å°n‚Üí‚àûan=0\\displaystyle \\lim_{n \\to \\infty} a_n=0n‚Üí‚àûlim‚Äãan‚Äã=0 y an‚â•an+1a_n \\geq a_{n+1}an‚Äã‚â•an+1‚Äã para todo nnn Convergencia absoluta\tSeries ‚àën=1‚àûan\\displaystyle \\sum_{n=1}^{\\infty} a_nn=1‚àë‚àû‚Äãan‚Äã con valores positivos y negativos\tSi ‚àën=1‚àû‚à£an‚à£\\displaystyle \\sum_{n=1}^{\\infty} \\lvert a_n \\rvertn=1‚àë‚àû‚Äã‚à£an‚Äã‚à£ converge, entonces ‚àën=1‚àûan\\displaystyle \\sum_{n=1}^{\\infty} a_nn=1‚àë‚àû‚Äãan‚Äã converge Test de la integral\t‚àën=1‚àûf(n)\\displaystyle \\sum_{n=1}^{\\infty} f(n)n=1‚àë‚àû‚Äãf(n)\tSi f(x)\\displaystyle f(x)f(x) es una funci√≥n decreciente y positiva para x‚â•1x \\geq 1x‚â•1, entonces ‚àën=1‚àûf(n)\\displaystyle \\sum_{n=1}^{\\infty} f(n)n=1‚àë‚àû‚Äãf(n) converge si y solo si ‚à´1‚àûf(x)dx\\displaystyle \\int_{1}^{\\infty} f(x) d x‚à´1‚àû‚Äãf(x)dx converge Test de la raz√≥n\tSeries ‚àën=1‚àûan\\displaystyle \\sum_{n=1}^{\\infty} a_nn=1‚àë‚àû‚Äãan‚Äã que especialmente son exponenciales o factoriales\tSi lim‚Å°n‚Üí‚àû‚à£an+1an‚à£=L\\displaystyle \\lim_{n \\to \\infty} \\left\\lvert \\frac{a_{n+1}}{a_n} \\right\\rvert=Ln‚Üí‚àûlim‚Äã‚Äãan‚Äãan+1‚Äã‚Äã‚Äã=L, entonces ‚àën=1‚àûan\\displaystyle \\sum_{n=1}^{\\infty} a_nn=1‚àë‚àû‚Äãan‚Äã converge si L&lt;1L&lt;1L&lt;1 y diverge si L&gt;1L&gt;1L&gt;1. Si L=1L = 1L=1, el test es inconcluso Test de la ra√≠z\tSeries ‚àën=1‚àûan\\displaystyle \\sum_{n=1}^{\\infty} a_nn=1‚àë‚àû‚Äãan‚Äã qie especialmente son exponenciales\tSi lim‚Å°n‚Üí‚àû‚à£an‚à£n=L\\displaystyle \\lim_{n \\to \\infty} \\sqrt[n]{\\lvert a_n \\rvert}=Ln‚Üí‚àûlim‚Äãn‚à£an‚Äã‚à£‚Äã=L, entonces ‚àën=1‚àûan\\displaystyle \\sum_{n=1}^{\\infty} a_nn=1‚àë‚àû‚Äãan‚Äã converge si L&lt;1L&lt;1L&lt;1 y diverge si L&gt;1L&gt;1L&gt;1. Si L=1L = 1L=1, el test es inconcluso  ","version":"Next","tagName":"h2"},{"title":"Ecuaciones de rectas y planos en el espacio‚Äã","type":1,"pageTitle":"C√°lculo II","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_II#ecuaciones-de-rectas-y-planos-en-el-espacio","content":" ","version":"Next","tagName":"h2"},{"title":"Rectas‚Äã","type":1,"pageTitle":"C√°lculo II","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_II#rectas","content":" La ecuaci√≥n vectorial de la recta est√° dada por  r‚Éó=r‚Éó0+tv‚Éó\\vec{r} = \\vec{r}_0 + t \\vec{v}r=r0‚Äã+tv  donde r‚Éó0\\vec{r}_0r0‚Äã es un punto de la recta y v‚Éó\\vec{v}v es un vector paralelo a la recta.  La ecuaci√≥n param√©trica de la recta est√° dada por  {x=x0+aty=y0+btz=z0+ct\\begin{cases} x = x_0 + at \\\\ y = y_0 + bt \\\\ z = z_0 + ct \\end{cases}‚é©‚é®‚éß‚Äãx=x0‚Äã+aty=y0‚Äã+btz=z0‚Äã+ct‚Äã  mientras que la ecuaci√≥n sim√©trica de la recta est√° dada por  x‚àíx0a=y‚àíy0b=z‚àíz0c\\frac{x-x_0}{a} = \\frac{y-y_0}{b} = \\frac{z-z_0}{c}ax‚àíx0‚Äã‚Äã=by‚àíy0‚Äã‚Äã=cz‚àíz0‚Äã‚Äã  donde (x0,y0,z0)(x_0, y_0, z_0)(x0‚Äã,y0‚Äã,z0‚Äã) es un punto de la recta y (a,b,c)(a, b, c)(a,b,c) es un vector paralelo a la recta.  Recta en el espacio  ","version":"Next","tagName":"h3"},{"title":"Planos‚Äã","type":1,"pageTitle":"C√°lculo II","url":"/apuntes-fundamentals/docs/Matem√°ticas/calculo_II#planos","content":" La ecuaci√≥n vectorial de un plano est√° dada por  n‚Éó‚ãÖ(r‚Éó‚àír‚Éó0)=0\\vec{n} \\cdot (\\vec{r} - \\vec{r}_0) = 0n‚ãÖ(r‚àír0‚Äã)=0  donde r‚Éó0\\vec{r}_0r0‚Äã es un punto del plano y n‚Éó\\vec{n}n es un vector normal al plano.  La ecuaci√≥n escalar de un plano est√° dada por  a(x‚àíx0)+b(y‚àíy0)+c(z‚àíz0)=0a(x-x_0) + b(y-y_0) + c(z-z_0) = 0a(x‚àíx0‚Äã)+b(y‚àíy0‚Äã)+c(z‚àíz0‚Äã)=0  donde (x0,y0,z0)(x_0, y_0, z_0)(x0‚Äã,y0‚Äã,z0‚Äã) es un punto del plano y (a,b,c)(a, b, c)(a,b,c) es un vector normal al plano.  Si se reescriben los t√©rminos de la ecuaci√≥n anterior, podemos establecer la ecuaci√≥n lineal del plano como  ax+by+cz=dax + by + cz = dax+by+cz=d  donde d=ax0+by0+cz0d = ax_0 + by_0 + cz_0d=ax0‚Äã+by0‚Äã+cz0‚Äã.  Plano en el espacio ","version":"Next","tagName":"h3"},{"title":"√Ålgebra lineal","type":0,"sectionRef":"#","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal","content":"","keywords":"","version":"Next"},{"title":"Ecuaciones lineales en √°lgebra lineal‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#ecuaciones-lineales-en-√°lgebra-lineal","content":" ","version":"Next","tagName":"h2"},{"title":"Operaciones elementales de fila‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#operaciones-elementales-de-fila","content":" Las operaciones elementales de fila son tres operaciones que se pueden realizar en las filas de una matriz:  (Reemplazo) Sustituir una fila por la suma de s√≠ misma y un m√∫ltiplo de otra fila.(Intercambio) Intercambiar dos filas.(Escalamiento) Multiplicar todos los elementos de una fila por una constante diferente de cero.  ","version":"Next","tagName":"h3"},{"title":"Forma escalonada de una matriz‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#forma-escalonada-de-una-matriz","content":" Una matriz rectangular est√° en forma escalonada (o forma escalonada por filas) si tiene las siguientes tres propiedades:  Todas las filas diferentes de cero est√°n arriba de las filas que solo contienen ceros.Cada entrada principal de una fila est√° en una columna a la derecha de la entrada principal de la fila superior.En una columna todas las entradas debajo de la entrada principal son ceros.  Si una matriz de forma escalonada satisface las siguientes condiciones adicionales, entonces est√° en forma escalonada reducida (o forma escalonada reducida por filas):  La entrada principal en cada fila diferente de cero es 111.Cada entrada principal 111 es la √∫nica entrada distinta de cero en su columna.  Por ejemplo, las matrices  [2‚àí32101‚àí480005/2]¬†y¬†[10029010160013]\\left[\\begin{array}{rrrc} 2 &amp; -3 &amp; 2 &amp; 1 \\\\ 0 &amp; 1 &amp; -4 &amp; 8 \\\\ 0 &amp; 0 &amp; 0 &amp; 5 / 2 \\end{array}\\right] \\text { y }\\left[\\begin{array}{llll} 1 &amp; 0 &amp; 0 &amp; 29 \\\\ 0 &amp; 1 &amp; 0 &amp; 16 \\\\ 0 &amp; 0 &amp; 1 &amp; 3 \\end{array}\\right]‚Äã200‚Äã‚àí310‚Äã2‚àí40‚Äã185/2‚Äã‚Äã¬†y¬†‚Äã100‚Äã010‚Äã001‚Äã29163‚Äã‚Äã  est√°n en forma escalonada y forma escalonada reducida, respectivamente.  De forma general, las matrices en forma escalonada pueden tener entradas principales (‚ñ†\\small\\blacksquare‚ñ†) con cualquier valor diferente de cero, pero las entradas con asterisco (‚àó*‚àó) pueden tener cualquier valor, incluyendo cero.  [‚ñ†‚àó‚àó‚àó0‚ñ†‚àó‚àó00000000]\\left[\\begin{array}{llll} \\small\\blacksquare &amp; * &amp; * &amp; * \\\\ 0 &amp; \\small\\blacksquare &amp; * &amp; * \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{array}\\right]‚Äã‚ñ†000‚Äã‚àó‚ñ†00‚Äã‚àó‚àó00‚Äã‚àó‚àó00‚Äã‚Äã  En cambio, las matrices en forma escalonada reducida tienen entradas principales iguales a 111 y hay ceros abajo y arriba de cada entrada principal 111.  [10‚àó‚àó01‚àó‚àó00000000]\\left[\\begin{array}{llll} 1 &amp; 0 &amp; * &amp; * \\\\ 0 &amp; 1 &amp; * &amp; * \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{array}\\right]‚Äã1000‚Äã0100‚Äã‚àó‚àó00‚Äã‚àó‚àó00‚Äã‚Äã  ","version":"Next","tagName":"h3"},{"title":"Unicidad de la forma escalonada reducida‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#unicidad-de-la-forma-escalonada-reducida","content":" Teorema Cada matriz es equivalente por filas a una, y solo a una, matriz escalonada reducida.  Si una matriz AAA es equivalente por filas a una matriz escalonada UUU, entonces UUU se llama una forma escalonada (o una forma escalonada por filas) de AAA; si UUU est√° en forma escalonada reducida, entonces UUU es la forma escalonada reducida de AAA.  ","version":"Next","tagName":"h3"},{"title":"Posiciones pivote‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#posiciones-pivote","content":" Una posici√≥n pivote en una matriz AAA es una ubicaci√≥n en AAA que corresponde a un 111 principal en la forma escalonada reducida de AAA. Una columna pivote es una columna de AAA que contiene una posici√≥n pivote.  En los ejemplos anteriores, los cuadrados (‚ñ†\\small\\blacksquare‚ñ†) identifican las posiciones pivote.  ","version":"Next","tagName":"h3"},{"title":"Algoritmo de reducci√≥n por filas‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#algoritmo-de-reducci√≥n-por-filas","content":" El algoritmo que sigue consta de cuatro pasos y produce una matriz en forma escalonada. Un quinto paso da por resultado una matriz en forma escalonada reducida.  Se inicia con la columna diferente de cero del extremo izquierdo. Esta es una columna pivote. La posici√≥n pivote se ubica en la parte superior.Seleccione como pivote una entrada diferente de cero en la columna pivote. Si es necesario, intercambie filas para mover esta entrada a la posici√≥n pivote.Utilice operaciones de remplazo de filas para crear ceros en todas las posiciones ubicadas debajo del pivote.Cubra (o ignore) la fila que contiene la posici√≥n pivote y cubra todas las filas, si las hay, por encima de esta. Aplique los pasos 1 a 3 a la submatriz restante. Repita el proceso hasta que no haya filas diferentes de cero por modificar.Empezando con la posici√≥n pivote del extremo derecho y trabajando hacia arriba y hacia la izquierda, genere ceros arriba de cada pivote. Si un pivote no es 1 , convi√©rtalo en 1 mediante una operaci√≥n de escalamiento.  La combinaci√≥n de los pasos 1 a 4 se conoce como fase progresiva del algoritmo de reducci√≥n por filas. El paso 5, que produce la √∫nica forma escalonada reducida, se conoce como fase regresiva.  Ejemplo: Algoritmo de reducci√≥n por filas Transforme la siguiente matriz a la forma escalonada, y luego a la forma escalonada reducida: [03‚àí664‚àí53‚àí78‚àí5893‚àí912‚àí9615]\\left[\\begin{array}{rrrrrr} 0 &amp; 3 &amp; -6 &amp; 6 &amp; 4 &amp; -5 \\\\ 3 &amp; -7 &amp; 8 &amp; -5 &amp; 8 &amp; 9 \\\\ 3 &amp; -9 &amp; 12 &amp; -9 &amp; 6 &amp; 15 \\end{array}\\right]‚Äã033‚Äã3‚àí7‚àí9‚Äã‚àí6812‚Äã6‚àí5‚àí9‚Äã486‚Äã‚àí5915‚Äã‚Äã Paso 1: Elegimos el pivote. Paso 2: Intercambiamos las filas 1 y 3. (O bien, tambi√©n se podr√≠an intercambiar las filas 1 y 2). Paso 3: Como paso preliminar, se podr√≠a dividir la fila superior entre el pivote, 333. Pero con dos n√∫meros 333 en la columna 1, esto es tan f√°cil como sumar la fila 1 multiplicada por ‚àí1-1‚àí1 a la fila 2. Paso 4: Con la fila 1 cubierta, el paso 1 muestra que la columna 2 es la pr√≥xima columna pivote; para el paso 2, seleccione como pivote la entrada &quot;superior&quot; en esa columna. En el paso 3, se podr√≠a insertar un paso adicional de dividir la fila &quot;superior&quot; de la submatriz entre el pivote, 222. En vez de ello, se suma la fila &quot;superior&quot; multiplicada por ‚àí3/2-3 / 2‚àí3/2 a la fila de abajo. Esto produce Para el paso 4, cuando se cubre la fila que contiene la segunda posici√≥n pivote, se obtiene una nueva submatriz con una sola fila: Los pasos 1 a 3 no necesitan aplicarse para esta submatriz, pues ya se ha alcanzado una forma escalonada para la matriz completa. Si se desea la forma escalonada reducida, se efect√∫a un paso m√°s. Paso 5: El pivote del extremo derecho est√° en la fila 3. Genere ceros sobre √©l, sumando m√∫ltiplos adecuados de la fila 3 a las filas 1 y 2. El siguiente pivote se encuentra en la fila 2 . Se escala esta fila dividi√©ndola entre el pivote. Cree un cero en la columna 2 sumando la fila 2 multiplicada por 9 a la fila 1. Finalmente, escale la fila 1 dividi√©ndola entre el pivote, 3. Esta es la forma escalonada reducida de la matriz original.  ","version":"Next","tagName":"h3"},{"title":"Soluciones de sistemas lineales‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#soluciones-de-sistemas-lineales","content":" El algoritmo de reducci√≥n por filas conduce directamente a una descripci√≥n expl√≠cita del conjunto soluci√≥n de un sistema lineal cuando se aplica a la matriz aumentada del sistema.  Suponga, por ejemplo, que la matriz aumentada de un sistema lineal se transform√≥ a la forma escalonada reducida equivalente  [10‚àí5101140000]\\left[\\begin{array}{rrrr}1 &amp; 0 &amp; -5 &amp; 1 \\\\ 0 &amp; 1 &amp; 1 &amp; 4 \\\\ 0 &amp; 0 &amp; 0 &amp; 0\\end{array}\\right]‚Äã100‚Äã010‚Äã‚àí510‚Äã140‚Äã‚Äã  Existen tres variables porque la matriz aumentada tiene cuatro columnas. El sistema de ecuaciones asociado es  x1‚àí5x3=1x2+x3=40=0\\begin{aligned} x_1-5 x_3 &amp; =1 \\\\ x_2+x_3 &amp; =4 \\\\ 0 &amp; =0 \\end{aligned}x1‚Äã‚àí5x3‚Äãx2‚Äã+x3‚Äã0‚Äã=1=4=0‚Äã  Las variables x1x_1x1‚Äã y x2x_2x2‚Äã correspondientes a las columnas pivote se conocen como variables b√°sicas. La otra variable, x3x_3x3‚Äã, se denomina variable libre.  Siempre que un sistema es consistente, como el anterior, el conjunto soluci√≥n se puede describir expl√≠citamente al despejar en el sistema de ecuaciones reducido las variables b√°sicas en t√©rminos de las variables libres. Esta operaci√≥n es posible porque la forma escalonada reducida coloca a cada variable b√°sica en una y solo una ecuaci√≥n. En el sistema anterior, despeje x1x_1x1‚Äã de la primera ecuaci√≥n y x2x_2x2‚Äã de la segunda. (Ignore la tercera ecuaci√≥n, ya que no ofrece restricciones sobre las variables).  {x1=1+5x3x2=4‚àíx3x3¬†es¬†libre¬†\\left\\{\\begin{array}{l} x_1=1+5 x_3 \\\\ x_2=4-x_3 \\\\ x_3 \\text { es libre } \\end{array}\\right.‚é©‚é®‚éß‚Äãx1‚Äã=1+5x3‚Äãx2‚Äã=4‚àíx3‚Äãx3‚Äã¬†es¬†libre¬†‚Äã  El enunciado &quot;x3x_3x3‚Äã es libre&quot; significa que existe libertad de elegir cualquier valor para x3x_3x3‚Äã. Una vez hecho esto, las f√≥rmulas anteriores determinan los valores de x1x_1x1‚Äã y x2x_2x2‚Äã. Por ejemplo, cuando x3=0x_3=0x3‚Äã=0, la soluci√≥n es (1,4,0)(1,4,0)(1,4,0); cuando x3=1x_3=1x3‚Äã=1, la soluci√≥n es (6,3,1)(6,3,1)(6,3,1). Cada asignaci√≥n diferente de x3x_3x3‚Äã determina una soluci√≥n (distinta) del sistema, y cada soluci√≥n del sistema est√° determinada por una asignaci√≥n de x3x_3x3‚Äã.  ","version":"Next","tagName":"h3"},{"title":"Preguntas de existencia y unicidad‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#preguntas-de-existencia-y-unicidad","content":" Teorema de existencia y unicidad Un sistema lineal es consistente si y solo si la columna m√°s a la derecha de la matriz aumentada no es una columna pivote, es decir, si y solo si una forma escalonada de la matriz aumentada no tiene filas del tipo [0‚ãØ0b]con¬†b¬†diferente¬†de¬†cero\\left[\\begin{array}{llll}0 &amp; \\cdots &amp; 0 &amp; b\\end{array}\\right] \\quad \\text{con } b \\text{ diferente de cero}[0‚Äã‚ãØ‚Äã0‚Äãb‚Äã]con¬†b¬†diferente¬†de¬†cero Si un sistema lineal es consistente, entonces el conjunto soluci√≥n contiene: i. una √∫nica soluci√≥n, cuando no existen variables libres, o ii. una infinidad de soluciones, cuando hay al menos una variable libre.  El siguiente procedimiento indica c√≥mo encontrar y describir todas las soluciones de un sistema lineal.  Escriba la matriz aumentada del sistema.Emplee el algoritmo de reducci√≥n por filas para obtener una matriz aumentada equivalente en forma escalonada. Determine si el sistema es consistente o no. Si no existe soluci√≥n, det√©ngase; en caso contrario, contin√∫e con el siguiente paso.Prosiga con la reducci√≥n por filas para obtener la forma escalonada reducida.Escriba el sistema de ecuaciones correspondiente a la matriz obtenida en el paso 3.Rescriba cada ecuaci√≥n no nula del paso 4 de manera que su √∫nica variable b√°sica se exprese en t√©rminos de cualquiera de las variables libres que aparecen en la ecuaci√≥n.  ","version":"Next","tagName":"h3"},{"title":"Combinaciones lineales‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#combinaciones-lineales","content":" Dados los vectores v1,v2,‚Ä¶,vp\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_pv1‚Äã,v2‚Äã,‚Ä¶,vp‚Äã en Rn\\mathbb{R}^nRn y dados los escalares c1,c2,‚Ä¶,cpc_1, c_2, \\ldots, c_pc1‚Äã,c2‚Äã,‚Ä¶,cp‚Äã, el vector y\\mathbf{y}y definido por  y=c1v1+‚ãØ+cpvp\\mathbf{y}=c_1 \\mathbf{v}_1+\\cdots+c_p \\mathbf{v}_py=c1‚Äãv1‚Äã+‚ãØ+cp‚Äãvp‚Äã  se llama combinaci√≥n lineal de v1,‚Ä¶,vp\\mathbf{v}_1, \\ldots, \\mathbf{v}_pv1‚Äã,‚Ä¶,vp‚Äã con pesos c1,‚Ä¶,cpc_1, \\ldots, c_pc1‚Äã,‚Ä¶,cp‚Äã.  La siguiente figura identifica combinaciones lineales seleccionadas de v1=[‚àí11]\\mathbf{v}_1=\\left[\\begin{array}{r}-1 \\\\ 1\\end{array}\\right]v1‚Äã=[‚àí11‚Äã]y v2=[21]\\mathbf{v}_2=\\left[\\begin{array}{l}2 \\\\ 1\\end{array}\\right]v2‚Äã=[21‚Äã].  Ejemplo de combinaci√≥n lineal  ","version":"Next","tagName":"h3"},{"title":"Espacio generado‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#espacio-generado","content":" Si v1,‚Ä¶,vp\\mathbf{v}_1, \\ldots, \\mathbf{v}_pv1‚Äã,‚Ä¶,vp‚Äã est√°n en Rn\\mathbb{R}^nRn, entonces el conjunto de todas las combinaciones lineales de v1,‚Ä¶,vp\\mathbf{v}_1, \\ldots, \\mathbf{v}_pv1‚Äã,‚Ä¶,vp‚Äã se denota como Gen{v1,‚Ä¶,vp}\\text{Gen}\\left\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_p\\right\\}Gen{v1‚Äã,‚Ä¶,vp‚Äã} y se llama el subconjunto de Rn\\mathbb{R}^nRn extendido o generado por v1,‚Ä¶,vp\\mathbf{v}_1, \\ldots, \\mathbf{v}_pv1‚Äã,‚Ä¶,vp‚Äã. Es decir, Gen{v1,‚Ä¶,vp}\\text{Gen}\\left\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_p\\right\\}Gen{v1‚Äã,‚Ä¶,vp‚Äã} es el conjunto de todos los vectores que se pueden escribir en la forma  c1v1+c2v2+‚ãØ+cpvpc_1 \\mathbf{v}_1+c_2 \\mathbf{v}_2+\\cdots+c_p \\mathbf{v}_pc1‚Äãv1‚Äã+c2‚Äãv2‚Äã+‚ãØ+cp‚Äãvp‚Äã  con escalares c1,‚Ä¶,cpc_1, \\ldots, c_pc1‚Äã,‚Ä¶,cp‚Äã.  Sea v\\mathbf{v}v un vector diferente de cero en R3\\mathbb{R}^3R3. Entonces Gen{v}\\text{Gen}\\{\\mathbf{v}\\}Gen{v} es el conjunto de todos los m√∫ltiplos escalares de v\\mathbf{v}v, que es el conjunto de puntos sobre la recta en R3\\mathbb{R}^3R3 que pasa por v\\mathbf{v}v y 0\\mathbf{0}0.  Si u\\mathbf{u}u y v\\mathbf{v}v son vectores diferentes de cero en R3\\mathbb{R}^3R3, y v\\mathbf{v}v no es un m√∫ltiplo de u\\mathbf{u}u, entonces Gen {u,v}\\{\\mathbf{u}, \\mathbf{v}\\}{u,v} es el plano en R3\\mathbb{R}^3R3 que contiene a u,v\\mathbf{u}, \\mathbf{v}u,v y 0\\mathbf{0}0. En particular, Gen {u,v}\\{\\mathbf{u}, \\mathbf{v}\\}{u,v} contiene la recta en R3\\mathbb{R}^3R3 que pasa por u\\mathbf{u}u y 0\\mathbf{0}0, y la recta que pasa por v\\mathbf{v}v y 0\\mathbf{0}0.  Espacio generado  ","version":"Next","tagName":"h3"},{"title":"Ecuaci√≥n matricial‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#ecuaci√≥n-matricial","content":" Si AAA es una matriz de m√ónm \\times nm√ón, con columnas a1,‚Ä¶,an\\mathbf{a}_1, \\ldots, \\mathbf{a}_na1‚Äã,‚Ä¶,an‚Äã, y si x\\mathbf{x}x est√° en Rn\\mathbb{R}^nRn, entonces el producto de AAA y x\\mathbf{x}x, denotado como AxA \\mathbf{x}Ax, es la combinaci√≥n lineal de las columnas de AAA utilizando como pesos las entradas correspondientes en x\\mathbf{x}x; es decir,  Ax=[a1a2‚ãØan][x1‚ãÆxn]=x1a1+x2a2+‚ãØ+xnanA \\mathbf{x}=\\left[\\begin{array}{llll} \\mathbf{a}_1 &amp; \\mathbf{a}_2 &amp; \\cdots &amp; \\mathbf{a}_n \\end{array}\\right]\\left[\\begin{array}{c} x_1 \\\\ \\vdots \\\\ x_n \\end{array}\\right]=x_1 \\mathbf{a}_1+x_2 \\mathbf{a}_2+\\cdots+x_n \\mathbf{a}_nAx=[a1‚Äã‚Äãa2‚Äã‚Äã‚ãØ‚Äãan‚Äã‚Äã]‚Äãx1‚Äã‚ãÆxn‚Äã‚Äã‚Äã=x1‚Äãa1‚Äã+x2‚Äãa2‚Äã+‚ãØ+xn‚Äãan‚Äã  Teorema Si AAA es una matriz de m√ónm \\times nm√ón, con columnas a1,‚Ä¶,an\\mathbf{a}_1, \\ldots, \\mathbf{a}_na1‚Äã,‚Ä¶,an‚Äã, y si b\\mathbf{b}b est√° en Rm\\mathbb{R}^mRm, la ecuaci√≥n matricial Ax=bA \\mathbf{x}=\\mathbf{b}Ax=b tiene el mismo conjunto soluci√≥n que la ecuaci√≥n vectorial x1a1+x2a2+‚ãØ+xnan=bx_1 \\mathbf{a}_1+x_2 \\mathbf{a}_2+\\cdots+x_n \\mathbf{a}_n=\\mathbf{b}x1‚Äãa1‚Äã+x2‚Äãa2‚Äã+‚ãØ+xn‚Äãan‚Äã=b la cual, a la vez, tiene el mismo conjunto soluci√≥n que el sistema de ecuaciones lineales cuya matriz aumentada es [a1a2‚ãØanb]\\left[\\begin{array}{lllll} \\mathbf{a}_1 &amp; \\mathbf{a}_2 &amp; \\cdots &amp; \\mathbf{a}_n &amp; \\mathbf{b} \\end{array}\\right][a1‚Äã‚Äãa2‚Äã‚Äã‚ãØ‚Äãan‚Äã‚Äãb‚Äã]  La definici√≥n de AxA \\mathbf{x}Ax conduce directamente al siguiente hecho que resulta √∫til:  Existencia de soluci√≥n La ecuaci√≥n Ax=bA \\mathbf{x}=\\mathbf{b}Ax=b tiene una soluci√≥n si y solo si b es una combinaci√≥n lineal de las columnas de AAA.  Dado lo anterior, podemos enunciar el siguiente teorema:  Teorema Sea AAA una matriz de m√ónm \\times nm√ón. Entonces, los siguientes enunciados son l√≥gicamente equivalentes. Es decir, para una AAA particular, todos los enunciados son verdaderos o todos son falsos. Para cada b\\mathbf{b}b en Rm\\mathbb{R}^mRm, la ecuaci√≥n Ax=bA \\mathbf{x}=\\mathbf{b}Ax=b tiene una soluci√≥n.Cada b\\mathbf{b}b en Rm\\mathbb{R}^mRm es una combinaci√≥n lineal de las columnas de AAA.Las columnas de AAA generan Rm\\mathbb{R}^mRm.AAA tiene una posici√≥n pivote en cada fila.  ","version":"Next","tagName":"h3"},{"title":"Sistemas lineales homog√©neos‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#sistemas-lineales-homog√©neos","content":" Se dice que un sistema de ecuaciones lineales es homog√©neo si se puede escribir en la forma Ax=0A \\mathbf{x}=\\mathbf{0}Ax=0, donde AAA es una matriz de m√ónm \\times nm√ón, y 0\\mathbf{0}0 es el vector cero en Rm\\mathbb{R}^mRm. Tal sistema Ax=0A \\mathbf{x}=\\mathbf{0}Ax=0 siempre tiene al menos una soluci√≥n, a saber, x=0\\mathbf{x}=\\mathbf{0}x=0 (el vector cero en Rn\\mathbb{R}^nRn ). Esta soluci√≥n cero generalmente se conoce como soluci√≥n trivial. Para una ecuaci√≥n dada Ax=0A \\mathbf{x}=\\mathbf{0}Ax=0, la pregunta importante es si existe una soluci√≥n no trivial, es decir, un vector x\\mathbf{x}x diferente de cero que satisfaga Ax=0A \\mathbf{x}=\\mathbf{0}Ax=0. El teorema de existencia y unicidad conduce de inmediato al siguiente resultado.  Resultado La ecuaci√≥n homog√©nea Ax=0A \\mathbf{x}=\\mathbf{0}Ax=0 tiene una soluci√≥n no trivial si y solo si la ecuaci√≥n tiene al menos una variable libre.  ","version":"Next","tagName":"h3"},{"title":"Independencia lineal‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#independencia-lineal","content":" Las ecuaciones homog√©neas se pueden estudiar desde una perspectiva diferente si las escribimos como ecuaciones vectoriales. De esta manera, la atenci√≥n se transfiere de las soluciones desconocidas de Ax=0A \\mathbf{x}=\\mathbf{0}Ax=0 a los vectores que aparecen en las ecuaciones vectoriales.  Por ejemplo, considere la ecuaci√≥n  x1[123]+x2[456]+x3[210]=[000]x_1\\left[\\begin{array}{l} 1 \\\\ 2 \\\\ 3 \\end{array}\\right]+x_2\\left[\\begin{array}{l} 4 \\\\ 5 \\\\ 6 \\end{array}\\right]+x_3\\left[\\begin{array}{l} 2 \\\\ 1 \\\\ 0 \\end{array}\\right]=\\left[\\begin{array}{l} 0 \\\\ 0 \\\\ 0 \\end{array}\\right]x1‚Äã‚Äã123‚Äã‚Äã+x2‚Äã‚Äã456‚Äã‚Äã+x3‚Äã‚Äã210‚Äã‚Äã=‚Äã000‚Äã‚Äã  Esta ecuaci√≥n tiene una soluci√≥n trivial, desde luego, donde x1=x2=x3=0x_1=x_2=x_3=0x1‚Äã=x2‚Äã=x3‚Äã=0. Al igual que hemos discutido antes, el asunto principal es si la soluci√≥n trivial es la √∫nica.  Definici√≥n Se dice que un conjunto indexado de vectores {v1,‚Ä¶,vp}\\left\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_p\\right\\}{v1‚Äã,‚Ä¶,vp‚Äã} en Rn\\mathbb{R}^nRn es linealmente independiente si la ecuaci√≥n vectorial x1v1+x2v2+‚ãØ+xpvp=0x_1 \\mathbf{v}_1+x_2 \\mathbf{v}_2+\\cdots+x_p \\mathbf{v}_p=\\mathbf{0}x1‚Äãv1‚Äã+x2‚Äãv2‚Äã+‚ãØ+xp‚Äãvp‚Äã=0 solo tiene la soluci√≥n trivial. Se dice que el conjunto {v1,‚Ä¶,vp}\\left\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_p\\right\\}{v1‚Äã,‚Ä¶,vp‚Äã} es linealmente dependiente si existen pesos c1,‚Ä¶,cpc_1, \\ldots, c_pc1‚Äã,‚Ä¶,cp‚Äã, no todos cero, tales que c1v1+c2v2+‚ãØ+cpvp=0c_1 \\mathbf{v}_1+c_2 \\mathbf{v}_2+\\cdots+c_p \\mathbf{v}_p=\\mathbf{0}c1‚Äãv1‚Äã+c2‚Äãv2‚Äã+‚ãØ+cp‚Äãvp‚Äã=0  La ecuaci√≥n que define el concepto de &quot;linealmente dependiente&quot; se llama relaci√≥n de dependencia lineal entre v1,‚Ä¶,vp\\mathbf{v}_1, \\ldots, \\mathbf{v}_pv1‚Äã,‚Ä¶,vp‚Äã cuando no todos los pesos son cero. Un conjunto indexado es linealmente dependiente si y solo si no es linealmente independiente. Por brevedad, puede decirse que v1,‚Ä¶,vp\\mathbf{v}_1, \\ldots, \\mathbf{v}_pv1‚Äã,‚Ä¶,vp‚Äã son linealmente dependientes cuando queremos decir que {v1,‚Ä¶,vp}\\left\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_p\\right\\}{v1‚Äã,‚Ä¶,vp‚Äã} es un conjunto linealmente dependiente. Se utiliza una terminolog√≠a semejante para los conjuntos linealmente independientes.  ","version":"Next","tagName":"h3"},{"title":"Independencia lineal en columnas de una matriz‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#independencia-lineal-en-columnas-de-una-matriz","content":" Suponga que, en vez de utilizar un conjunto de vectores, se inicia con una matriz A=[a1‚ãØan]A=\\left[\\begin{array}{lll}\\mathbf{a}_1 &amp; \\cdots &amp; \\mathbf{a}_n\\end{array}\\right]A=[a1‚Äã‚Äã‚ãØ‚Äãan‚Äã‚Äã]. En tal caso, la ecuaci√≥n matricial Ax=0A \\mathbf{x}=\\mathbf{0}Ax=0 se puede escribir como  x1a1+x2a2+‚ãØ+xnan=0x_1 \\mathbf{a}_1+x_2 \\mathbf{a}_2+\\cdots+x_n \\mathbf{a}_n=\\mathbf{0}x1‚Äãa1‚Äã+x2‚Äãa2‚Äã+‚ãØ+xn‚Äãan‚Äã=0  Cada relaci√≥n de dependencia lineal entre las columnas de A corresponde a una soluci√≥n no trivial de Ax=0A \\mathbf{x}=\\mathbf{0}Ax=0. As√≠, tenemos el siguiente resultado importante.  Teorema Las columnas de una matriz AAA son linealmente independientes si y solo si la ecuaci√≥n Ax=0A \\mathbf{x}=\\mathbf{0}Ax=0 tiene solo la soluci√≥n trivial.  ","version":"Next","tagName":"h3"},{"title":"Geometr√≠a de la dependencia lineal‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#geometr√≠a-de-la-dependencia-lineal","content":" Siempre es posible determinar por inspecci√≥n cu√°ndo un conjunto de dos vectores es linealmente dependiente. Las operaciones de fila son innecesarias. Basta con comprobar si al menos uno de los vectores es un escalar multiplicado por el otro. (La prueba solo se aplica a conjuntos de dos vectores).  Dependencia lineal entre dos vectores Un conjunto de dos vectores {v1,v2}\\left\\{\\mathbf{v}_1, \\mathbf{v}_2\\right\\}{v1‚Äã,v2‚Äã} es linealmente dependiente si al menos uno de los vectores es un m√∫ltiplo del otro. El conjunto es linealmente independiente si y solo si ninguno de los vectores es un m√∫ltiplo del otro.  Dependencia lineal  En t√©rminos geom√©tricos, dos vectores son linealmente dependientes si y solo si ambos est√°n sobre la misma recta que pasa por el origen.  Para dos o m√°s vectores, tenemos el siguiente resultado:  Caracterizaci√≥n de conjuntos linealmente dependientes Un conjunto indexado S={v1,‚Ä¶,vp}S=\\left\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_p\\right\\}S={v1‚Äã,‚Ä¶,vp‚Äã} de dos o m√°s vectores es linealmente dependiente si y solo si al menos uno de los vectores en SSS es una combinaci√≥n lineal de los otros. De hecho, si SSS es linealmente dependiente y v1‚â†0\\mathbf{v}_1 \\neq \\mathbf{0}v1‚ÄãÓÄ†=0, entonces alguna vj(con‚Å°j&gt;1\\mathbf{v}_j(\\operatorname{con} j&gt;1vj‚Äã(conj&gt;1 ) es una combinaci√≥n lineal de los vectores precedentes, v1,‚Ä¶,vj‚àí1\\mathbf{v}_1, \\ldots, \\mathbf{v}_{j-1}v1‚Äã,‚Ä¶,vj‚àí1‚Äã.  Los siguientes dos teoremas describen casos especiales en los cuales la dependencia lineal de un conjunto es autom√°tica.  Teorema Si un conjunto contiene m√°s vectores que entradas en cada vector, entonces el conjunto es linealmente dependiente. Es decir, cualquier conjunto {v1,‚Ä¶,vp}\\left\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_p\\right\\}{v1‚Äã,‚Ä¶,vp‚Äã} en Rn\\mathbb{R}^nRn es linealmente dependiente si p&gt;np&gt;np&gt;n.  Teorema Si un conjunto S={v1,‚Ä¶,vp}S=\\left\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_p\\right\\}S={v1‚Äã,‚Ä¶,vp‚Äã} en Rn\\mathbb{R}^nRn contiene al vector cero, entonces el conjunto es linealmente dependiente.  ","version":"Next","tagName":"h3"},{"title":"Transformaciones lineales‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#transformaciones-lineales","content":" La correspondencia de x\\mathbf{x}x a AxA\\mathbf{x}Ax es una funci√≥n de un conjunto de vectores a otro. Este concepto generaliza la noci√≥n com√∫n de una funci√≥n como una regla que transforma un n√∫mero real en otro.  Una transformaci√≥n (o funci√≥n o mapeo) TTT de Rn\\mathbb{R}^nRn a Rm\\mathbb{R}^mRm es una regla que asigna a cada vector x\\mathbf{x}x en Rn\\mathbb{R}^nRn un vector T(x)T(\\mathbf{x})T(x) en Rm\\mathbb{R}^mRm. El conjunto Rn\\mathbb{R}^nRn se llama el dominio de TTT, y Rm\\mathbb{R}^mRm se llama el codominio de TTT. La notaci√≥n T:Rn‚ÜíRmT: \\mathbb{R}^n \\rightarrow \\mathbb{R}^mT:Rn‚ÜíRm indica que el dominio de TTT es Rn\\mathbb{R}^nRn y que el codominio es Rm\\mathbb{R}^mRm. Para x\\mathbf{x}x en Rn\\mathbb{R}^nRn, el vector T(x)T(\\mathbf{x})T(x) en Rm\\mathbb{R}^mRm es la imagen de x\\mathbf{x}x (bajo la acci√≥n de TTT ). El conjunto de todas las im√°genes T(x)T(\\mathbf{x})T(x) es el rango de TTT.    Para cada x\\mathbf{x}x en Rn,T(x)\\mathbb{R}^n, T(\\mathbf{x})Rn,T(x) se calcula como AxA \\mathbf{x}Ax, donde AAA es una matriz de m√ónm \\times nm√ón. Para simplificar, algunas veces esta transformaci√≥n matricial se denota como x‚Ü¶Ax\\mathbf{x} \\mapsto A \\mathbf{x}x‚Ü¶Ax. Observe que el dominio de TTT es Rn\\mathbb{R}^nRn cuando AAA tiene nnn columnas, y el codominio de TTT es Rm\\mathbb{R}^mRm cuando cada columna de AAA tiene mmm entradas. El rango de TTT es el conjunto de todas las combinaciones lineales de las columnas de AAA, porque cada imagen T(x)T(\\mathbf{x})T(x) es de la forma AxA \\mathbf{x}Ax.  Definici√≥n Una transformaci√≥n (o mapeo) TTT es lineal si: T(u+v)=T(u)+T(v)T(\\mathbf{u}+\\mathbf{v})=T(\\mathbf{u})+T(\\mathbf{v})T(u+v)=T(u)+T(v) para todas las u\\mathbf{u}u, v\\mathbf{v}v en el dominio de TTT;T(cu)=cT(u)T(c \\mathbf{u})=c T(\\mathbf{u})T(cu)=cT(u) para todos los escalares ccc y para todas las u\\mathbf{u}u en el dominio de TTT.  ","version":"Next","tagName":"h3"},{"title":"√Ålgebra de matrices‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#√°lgebra-de-matrices","content":" ","version":"Next","tagName":"h2"},{"title":"Operaciones b√°sicas‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#operaciones-b√°sicas","content":" Sean A,BA, BA,B y CCC matrices del mismo tama√±o, y sean rrr y sss escalares.  A+B=B+AA+B=B+AA+B=B+Ar(A+B)=rA+rBr(A+B)=r A+r Br(A+B)=rA+rB(A+B)+C=A+(B+C)(A+B)+C=A+(B+C)(A+B)+C=A+(B+C)(r+s)A=rA+sA(r+s) A=r A+s A(r+s)A=rA+sAA+0=AA+0=AA+0=Ar(sA)=(rs)Ar(s A)=(r s) Ar(sA)=(rs)AAk=A‚ãØA‚èükA^k=\\underbrace{A \\cdots A}_kAk=kA‚ãØA‚Äã‚Äã  ","version":"Next","tagName":"h3"},{"title":"Multiplicaci√≥n de matrices‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#multiplicaci√≥n-de-matrices","content":" Si AAA es una matriz de m√ónm \\times nm√ón, y si BBB es una matriz de n√ópn \\times pn√óp con columnas b1,‚Ä¶,bp\\mathbf{b}_1, \\ldots, \\mathbf{b}_pb1‚Äã,‚Ä¶,bp‚Äã entonces el producto ABA BAB es la matriz de m√ópm \\times pm√óp cuyas columnas son Ab1,‚Ä¶,AbpA \\mathbf{b}_1, \\ldots, A \\mathbf{b}_pAb1‚Äã,‚Ä¶,Abp‚Äã. Es decir,  AB=A[b1b2‚ãØbp]=[Ab1Ab2‚ãØAbp]A B=A\\left[\\begin{array}{llll} \\mathbf{b}_1 &amp; \\mathbf{b}_2 &amp; \\cdots &amp; \\mathbf{b}_p \\end{array}\\right]=\\left[\\begin{array}{llll} A \\mathbf{b}_1 &amp; A \\mathbf{b}_2 &amp; \\cdots &amp; A \\mathbf{b}_p \\end{array}\\right]AB=A[b1‚Äã‚Äãb2‚Äã‚Äã‚ãØ‚Äãbp‚Äã‚Äã]=[Ab1‚Äã‚ÄãAb2‚Äã‚Äã‚ãØ‚ÄãAbp‚Äã‚Äã]  Es decir, cada columna de ABA BAB es una combinaci√≥n lineal de las columnas de AAA usando pesos de la columna correspondiente de BBB.  Regla fila-columna para calcular AB Si el producto ABA BAB est√° definido, entonces la entrada en la fila iii y la columna jjj de ABA BAB es la suma de los productos de las entradas correspondientes de la fila iii de AAA y la columna jjj de BBB. Si (AB)ij(A B)_{i j}(AB)ij‚Äã denota la entrada (i,j)(i, j)(i,j) en ABA BAB, y si AAA es una matriz de m√ónm \\times nm√ón, entonces (AB)ij=ai1b1j+ai2b2j+‚ãØ+ainbnj(A B)_{i j}=a_{i 1} b_{1 j}+a_{i 2} b_{2 j}+\\cdots+a_{i n} b_{n j}(AB)ij‚Äã=ai1‚Äãb1j‚Äã+ai2‚Äãb2j‚Äã+‚ãØ+ain‚Äãbnj‚Äã  Propiedades de la multiplicaci√≥n de matrices Sea AAA una matriz de m√ónm \\times nm√ón, y sean BBB y CCC matrices con tama√±os para los que las sumas y los productos indicados est√°n definidos. A(BC)=(AB)CA(B C)=(A B) CA(BC)=(AB)CA(B+C)=AB+ACA(B+C)=A B+A CA(B+C)=AB+AC(B+C)A=BA+CA(B+C) A=B A+C A(B+C)A=BA+CAr(AB)=(rA)B=A(rB)r(A B)=(r A) B=A(r B)r(AB)=(rA)B=A(rB) para cualquier escalar rrrImA=A=AInI_m A=A=A I_nIm‚ÄãA=A=AIn‚Äã  Advertencias En general, AB‚â†BAA B \\neq B AABÓÄ†=BA.Las leyes de la cancelaci√≥n no se aplican en la multiplicaci√≥n de matrices. Es decir, si AB=ACA B=A CAB=AC, en general no es cierto que B=CB=CB=C.Si un producto ABA BAB es la matriz cero, en general, no se puede concluir que A=0A=0A=0 o B=0B=0B=0.  ","version":"Next","tagName":"h3"},{"title":"La transpuesta de una matriz‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#la-transpuesta-de-una-matriz","content":" Dada una matriz AAA de m√ónm \\times nm√ón, la transpuesta de AAA es la matriz de n√ómn \\times mn√óm, que se denota con ATA^TAT, cuyas columnas se forman a partir de las filas correspondientes de AAA.  Teorema Sean AAA y BBB matrices cuyos tama√±os son adecuados para las siguientes sumas y productos. (AT)T=A\\left(A^T\\right)^T=A(AT)T=A(A+B)T=AT+BT(A+B)^T=A^T+B^T(A+B)T=AT+BTPara cualquier escalar r,(rA)T=rATr,(r A)^T=r A^Tr,(rA)T=rAT(AB)T=BTAT(A B)^T=B^T A^T(AB)T=BTAT  ","version":"Next","tagName":"h3"},{"title":"Inversa de una matriz‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#inversa-de-una-matriz","content":" Se dice que una matriz AAA de n√ónn \\times nn√ón es invertible si existe otra matriz A‚àí1A^{-1}A‚àí1 de n√ónn \\times nn√ón tal que  A‚àí1A=I¬†y¬†AA‚àí1=IA^{-1} A=I \\quad \\text { y } \\quad A A^{-1}=IA‚àí1A=I¬†y¬†AA‚àí1=I  donde I=InI=I_nI=In‚Äã, la matriz identidad de n√ónn \\times nn√ón. En este caso, A‚àí1A^{-1}A‚àí1 es una inversa de AAA.  Teorema Sea A=[abcd]A=\\left[\\begin{array}{ll}a &amp; b \\\\ c &amp; d\\end{array}\\right]A=[ac‚Äãbd‚Äã]. Si ad‚àíbc‚â†0a d-b c \\neq 0ad‚àíbcÓÄ†=0, entonces AAA es invertible y A‚àí1=1det(A)[d‚àíb‚àíca]A^{-1}=\\frac{1}{\\text{det}(A)}\\left[\\begin{array}{rr} d &amp; -b \\\\ -c &amp; a \\end{array}\\right]A‚àí1=det(A)1‚Äã[d‚àíc‚Äã‚àíba‚Äã] Si det(A)=ad‚àíbc=0\\text{det}(A)=a d-b c=0det(A)=ad‚àíbc=0, entonces AAA no es invertible.  La definici√≥n de matriz inversa nos entrega el siguiente teorema:  Teorema Si AAA es una matriz invertible de n√ónn \\times nn√ón, entonces, para cada b\\mathbf{b}b en Rn\\mathbb{R}^nRn, la ecuaci√≥n Ax=bA \\mathbf{x}=\\boldsymbol{b}Ax=b tiene la soluci√≥n √∫nica x=A‚àí1b\\mathbf{x}=A^{-1} \\mathbf{b}x=A‚àí1b.  Adem√°s, podemos definir las siguientes propiedades para matrices invertibles:  Si AAA es una matriz invertible, entonces A‚àí1A^{-1}A‚àí1 es invertible y(A‚àí1)‚àí1=A\\left(A^{-1}\\right)^{-1}=A(A‚àí1)‚àí1=ASi AAA y BBB son matrices invertibles de n√ónn \\times nn√ón, entonces tambi√©n lo es ABA BAB, y la inversa de ABA BAB es el producto de las inversas de AAA y BBB en el orden opuesto. Es decir,(AB)‚àí1=B‚àí1A‚àí1(A B)^{-1}=B^{-1} A^{-1}(AB)‚àí1=B‚àí1A‚àí1Si AAA es una matriz invertible, tambi√©n lo es ATA^TAT, y la inversa de ATA^TAT es la transpuesta de A‚àí1A^{-1}A‚àí1. Es decir,(AT)‚àí1=(A‚àí1)T\\left(A^T\\right)^{-1}=\\left(A^{-1}\\right)^T(AT)‚àí1=(A‚àí1)T  ","version":"Next","tagName":"h3"},{"title":"Matrices elementales‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#matrices-elementales","content":" Una matriz elemental es aquella que se obtiene al realizar una √∫nica operaci√≥n elemental de fila sobre una matriz identidad. El siguiente ejemplo ilustra los tres tipos de matrices elementales.  Si se realiza una operaci√≥n elemental de fila con una matriz AAA de m√ónm \\times nm√ón, la matriz resultante se puede escribir como EAE AEA, donde la matriz EEE de m√ómm \\times mm√óm se crea al realizar la misma operaci√≥n de fila sobre ImI_mIm‚Äã.  Por ejemplo, si    entonces    Al sumar a la fila 3 la fila 1 de AAA multiplicada por ‚àí4-4‚àí4 , se obtiene E1AE_1 AE1‚ÄãA. (Esta es una operaci√≥n de remplazo de filas). Con un intercambio de las filas 1 y 2 de AAA se obtiene E2AE_2 AE2‚ÄãA, y multiplicando la fila 3 de AAA por 555 se obtiene E3AE_3 AE3‚ÄãA.  Teorema Toda matriz elemental EEE es invertible. La inversa de EEE es la matriz elemental del mismo tipo que transforma a EEE de nuevo en III. Una matriz AAA de n√ónn \\times nn√ón es invertible si y solo si AAA es equivalente por filas a InI_nIn‚Äã, y, en este caso, cualquier secuencia de operaciones elementales de fila que reduzca AAA a InI_nIn‚Äã tambi√©n transforma a InI_nIn‚Äã en A‚àí1A^{-1}A‚àí1.  El teorema anterior nos da el siguiente algoritmo para determinar la inversa de una matriz AAA de n√ónn \\times nn√ón:  Algoritmo para determinar la inversa de una matriz Reduzca por filas la matriz aumentada [AI]\\left[\\begin{array}{ll}A &amp; I\\end{array}\\right][A‚ÄãI‚Äã]. Si AAA es equivalente por filas a III, entonces [AI]\\left[\\begin{array}{ll}A &amp; I\\end{array}\\right][A‚ÄãI‚Äã] es equivalente por filas a [IA‚àí1]\\left[\\begin{array}{ll}I &amp; A^{-1}\\end{array}\\right][I‚ÄãA‚àí1‚Äã]. De otra manera, AAA no tiene inversa.  ","version":"Next","tagName":"h3"},{"title":"El teorema de la matriz invertible‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#el-teorema-de-la-matriz-invertible","content":" El resultado principal de todo el estudio anterior es el siguiente teorema.  Teorema Sea AAA una matriz cuadrada de n√ónn \\times nn√ón. Entonces, los siguientes enunciados son equivalentes. Es decir, para una AAA dada, los enunciados son todos ciertos o todos falsos. AAA es una matriz invertible.AAA es equivalente por filas a la matriz identidad de n√ónn \\times nn√ón.AAA tiene nnn posiciones pivote.La ecuaci√≥n Ax=0A \\mathbf{x}=\\mathbf{0}Ax=0 tiene solamente la soluci√≥n trivial.Las columnas de AAA forman un conjunto linealmente independiente.La transformaci√≥n lineal x‚Ü¶Ax\\mathbf{x} \\mapsto A \\mathbf{x}x‚Ü¶Ax es uno a uno.La ecuaci√≥n Ax=bA \\mathbf{x}=\\mathbf{b}Ax=b tiene al menos una soluci√≥n para toda b\\mathbf{b}b en Rn\\mathbb{R}^nRn.Las columnas de AAA generan Rn\\mathbb{R}^nRn.La transformaci√≥n lineal x‚Ü¶Ax\\mathbf{x} \\mapsto A \\mathbf{x}x‚Ü¶Ax mapea Rn\\mathbb{R}^nRn sobre Rn\\mathbb{R}^nRn.Existe una matriz CCC de n√ónn \\times nn√ón tal que CA=IC A=ICA=I,Existe una matriz DDD de n√ónn \\times nn√ón tal que AD=IA D=IAD=I.ATA^TAT es una matriz invertible.  ","version":"Next","tagName":"h3"},{"title":"Transformaci√≥n lineal invertible‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#transformaci√≥n-lineal-invertible","content":" Se dice que una transformaci√≥n lineal T:Rn‚ÜíRnT: \\mathbb{R}^n \\rightarrow \\mathbb{R}^nT:Rn‚ÜíRn es invertible si existe una funci√≥n S:Rn‚ÜíRnS: \\mathbb{R}^n \\rightarrow \\mathbb{R}^nS:Rn‚ÜíRn tal que  S(T(x))=x¬†para¬†toda¬†x¬†en¬†RnT(S(x))=x¬†para¬†toda¬†x¬†en¬†Rn\\begin{array}{ll} S(T(\\mathbf{x}))=\\mathbf{x} &amp; \\text { para toda } \\mathbf{x} \\text { en } \\mathbb{R}^n \\\\ T(S(\\mathbf{x}))=\\mathbf{x} &amp; \\text { para toda } \\mathbf{x} \\text { en } \\mathbb{R}^n \\end{array}S(T(x))=xT(S(x))=x‚Äã¬†para¬†toda¬†x¬†en¬†Rn¬†para¬†toda¬†x¬†en¬†Rn‚Äã  El siguiente teorema establece que si dicha SSS existe, es √∫nica y debe ser una transformaci√≥n lineal. Se dice que SSS es la inversa de TTT y se escribe como T‚àí1T^{-1}T‚àí1.  Teorema Sea T:Rn‚ÜíRnT: \\mathbb{R}^n \\rightarrow \\mathbb{R}^nT:Rn‚ÜíRn una transformaci√≥n lineal y sea AAA la matriz est√°ndar para TTT. As√≠, TTT es invertible si y solo si AAA es una matriz invertible. En tal caso, la transformaci√≥n lineal SSS dada por S(x)=A‚àí1xS(\\mathbf{x})=A^{-1} \\mathbf{x}S(x)=A‚àí1x es la √∫nica funci√≥n que satisface las ecuaciones mostradas.  ","version":"Next","tagName":"h3"},{"title":"Subespacios‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#subespacios","content":" Un subespacio de Rn\\mathbb{R}^nRn es cualquier conjunto HHH en Rn\\mathbb{R}^nRn que tenga tres propiedades:  El vector cero est√° en HHH.Para cada u\\mathbf{u}u y v\\mathbf{v}v en HHH, la suma u+v\\mathbf{u}+\\mathbf{v}u+v est√° en HHH.Para cada u\\mathbf{u}u en HHH y cada escalar ccc, el vector cuc \\mathbf{u}cu est√° en HHH.  Dicho con palabras, un subespacio es cerrado bajo la suma y la multiplicaci√≥n escalar.    ","version":"Next","tagName":"h3"},{"title":"Espacio de columnas‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#espacio-de-columnas","content":" Los subespacios de Rn\\mathbb{R}^nRn generalmente se presentan en aplicaciones y en la teor√≠a en una de dos formas. En ambos casos, es posible relacionar el subespacio con una matriz.  Definici√≥n El espacio de columnas de una matriz AAA es el conjunto ColA\\mathrm{Col} AColA de todas las combinaciones de las columnas de AAA.  Si A=[a1‚ãØan]A=\\left[\\begin{array}{lll}\\mathbf{a}_1 &amp; \\cdots &amp; \\mathbf{a}_n\\end{array}\\right]A=[a1‚Äã‚Äã‚ãØ‚Äãan‚Äã‚Äã], con las columnas en Rm\\mathbb{R}^mRm, entonces ColA\\text{Col} AColA es lo mismo que Gen{a1,‚Ä¶,an}\\text{Gen}\\left\\{\\mathbf{a}_1, \\ldots, \\mathbf{a}_n\\right\\}Gen{a1‚Äã,‚Ä¶,an‚Äã}. De hecho, el espacio columna de una matriz de m√ón\\boldsymbol{m} \\times \\boldsymbol{n}m√ón es un subespacio de Rm\\mathbb{R}^mRm. Observe que ColA\\text{Col} AColA es igual a Rm\\mathbb{R}^mRm solo cuando las columnas de AAA generan a Rm\\mathbb{R}^mRm. Si no la generan, ColA\\text{Col}AColA es solo una parte de Rm\\mathbb{R}^mRm.  Cuando un sistema de ecuaciones lineales est√° escrito en la forma Ax=bA \\mathbf{x}=\\mathbf{b}Ax=b, el espacio columna de AAA es el conjunto de todas las b\\mathbf{b}b para las que el sistema tiene una soluci√≥n.  ","version":"Next","tagName":"h3"},{"title":"Espacio nulo‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#espacio-nulo","content":" El espacio nulo de una matriz AAA es el conjunto NulA\\mathrm{Nul} ANulA de todas las soluciones posibles para la ecuaci√≥n homog√©nea Ax=0A \\mathbf{x}=\\mathbf{0}Ax=0.  Cuando AAA tiene nnn columnas, las soluciones de Ax=0A \\mathbf{x}=\\mathbf{0}Ax=0 pertenecen a Rn\\mathbb{R}^nRn, y el espacio nulo de AAA es un subconjunto de Rn\\mathbb{R}^nRn. De hecho, Nul AAA tiene las propiedades de un subespacio de matrices de Rn\\mathbb{R}^nRn.  Teorema El espacio nulo de una matriz AAA de m√ónm \\times nm√ón es un subespacio de Rn\\mathbb{R}^nRn. De manera equivalente, el conjunto de todas las soluciones posibles para un sistema Ax=0A \\mathbf{x}=\\mathbf{0}Ax=0 de mmm ecuaciones lineales homog√©neas con nnn inc√≥gnitas es un subespacio de Rn\\mathbb{R}^nRn.  ","version":"Next","tagName":"h3"},{"title":"Base para un subespacio‚Äã","type":1,"pageTitle":"√Ålgebra lineal","url":"/apuntes-fundamentals/docs/Matem√°ticas/algebra_lineal#base-para-un-subespacio","content":" Como, por lo general, un subespacio contiene un n√∫mero infinito de vectores, algunos problemas relacionados con subespacios se manejan mejor trabajando con un conjunto finito y peque√±o de vectores que genere el subespacio. Cuanto menor sea el conjunto, ser√° mejor. Es factible demostrar que el conjunto generador m√°s peque√±o posible debe ser linealmente independiente.  Definici√≥n Una base de un subespacio HHH de Rn\\mathbb{R}^nRn es un conjunto linealmente independiente en HHH, que genera a HHH.  La base est√°ndar para todo el espacio  warning Solo son 4 preguntas de Lineal, despu√©s me sigo pegando el show terminando esto üò¢ ","version":"Next","tagName":"h3"},{"title":"Probabilidades y Estad√≠stica","type":0,"sectionRef":"#","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica","content":"","keywords":"","version":"Next"},{"title":"Teor√≠a de conjuntos‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#teor√≠a-de-conjuntos","content":" ","version":"Next","tagName":"h2"},{"title":"Definiciones importantes‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#definiciones-importantes","content":" Consideremos algunas definiciones relacionadas a un fen√≥meno aleatorio:  Espacio muestral: Conjunto de todos los resultados posibles.Punto muestral: Un resultado particular.Evento: Subconjunto de resultados posibles.  El espacio muestral puede ser discreto o continuo. El caso discreto corresponde a un espacio muestral compuesto por un conjunto contable (numerable) de puntos muestrales, mientras que el caso continuo corresponde a un espacio muestral compuesto de un continuo de puntos muestrales.  Evento Imposible: Denotado por œï\\phiœï es un evento sin puntos muestrales. Evento Certeza: Denotado por SSS u Œ©\\OmegaŒ©, es un evento que contiene a todos los puntos muestrales. Evento Complemento: Denotado por EÀâ\\bar{E}EÀâ, contiene todos los puntos muestrales de SSS que no est√°n contenidos en un evento EEE. Uni√≥n de Eventos: Para dos eventos E1E_1E1‚Äã y E2E_2E2‚Äã, su union forma un nuevo evento que contiene los puntos muestrales de E1E_1E1‚Äã y los contenidos en E2E_2E2‚Äã que no se encuentran en E1E_1E1‚Äã. Intersecci√≥n de Eventos: Para dos eventos E1E_1E1‚Äã y E2E_2E2‚Äã, su intersecci√≥n forma un nuevo evento que contiene los puntos muestrales contenidos en E1E_1E1‚Äã y en E2E_2E2‚Äã a la vez. Eventos Mutuamente Excluyentes (Disjuntos): Son eventos que no tienen puntos muestrales en com√∫n, es decir, su intersecci√≥n es vac√≠a. Eventos Colectivamente Exhaustivos: Son eventos que unidos conforman el espacio muestral.  U:¬†UnioÀän‚à©:¬†InterseccioÀänEÀâ:¬†Complemento¬†de¬†E\\begin{align*} U: &amp; \\text{ Uni√≥n} \\\\ \\cap: &amp; \\text{ Intersecci√≥n} \\\\ \\bar{E}: &amp; \\text{ Complemento de } E \\\\ \\end{align*}U:‚à©:EÀâ:‚Äã¬†UnioÀän¬†InterseccioÀän¬†Complemento¬†de¬†E‚Äã  ","version":"Next","tagName":"h3"},{"title":"Operaciones matem√°ticas de conjuntos‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#operaciones-matem√°ticas-de-conjuntos","content":" Igualdad de Conjuntos: Dos conjuntos son iguales si y s√≥lo si ambos conjuntos contienen exactamente los mismos puntos muestrales. Un caso b√°sico es el siguiente A‚à™œï=AA \\cup \\phi=AA‚à™œï=A donde œï\\phiœï representa un conjunto vac√≠o. Tambi√©n se tiene que A‚à©œï=œïA \\cap \\phi=\\phiA‚à©œï=œï Por lo tanto A‚à™A=A¬†y¬†A‚à©A=AA \\cup A=A \\quad \\text { y } A \\cap A=AA‚à™A=A¬†y¬†A‚à©A=A Con respecto al espacio muestral SSS A‚à™S=S¬†y¬†A‚à©S=AA \\cup S=S \\quad \\text { y } A \\cap S=AA‚à™S=S¬†y¬†A‚à©S=A Conjunto complemento: Con respecto a un evento EEE y su complemento EÀâ\\bar{E}EÀâ, se observa que E‚à™EÀâ=S¬†y¬†E‚à©EÀâ=œïE \\cup \\bar{E}=S \\quad \\text { y } \\quad E \\cap \\bar{E}=\\phiE‚à™EÀâ=S¬†y¬†E‚à©EÀâ=œï Finalmente EÀâ‚Äæ=E\\overline{\\bar{E}}=EEÀâ=E Ley Conmutativa: La uni√≥n e intersecci√≥n de conjuntos son conmutativas, es decir, para dos conjuntos AAA y BBB se cumple que A‚à™B=B‚à™AA‚à©B=B‚à©A\\begin{aligned} &amp; A \\cup B=B \\cup A \\\\ &amp; A \\cap B=B \\cap A \\end{aligned}‚ÄãA‚à™B=B‚à™AA‚à©B=B‚à©A‚Äã Ley Asociativa: La uni√≥n e intersecci√≥n de conjuntos es asociativa, es decir, para tres conjuntos A,BA, BA,B y CCC se cumple que (A‚à™B)‚à™C=A‚à™(B‚à™C)=B‚à™(A‚à™C)(A‚à©B)‚à©C=A‚à©(B‚à©C)=B‚à©(A‚à©C)\\begin{aligned} &amp; (A \\cup B) \\cup C=A \\cup(B \\cup C)=B \\cup(A \\cup C) \\\\ &amp; (A \\cap B) \\cap C=A \\cap(B \\cap C)=B \\cap(A \\cap C) \\end{aligned}‚Äã(A‚à™B)‚à™C=A‚à™(B‚à™C)=B‚à™(A‚à™C)(A‚à©B)‚à©C=A‚à©(B‚à©C)=B‚à©(A‚à©C)‚Äã Ley Distributiva: La uni√≥n e intersecci√≥n de conjuntos es distributiva, es decir, para tres conjuntos A,BA, BA,B y CCC se cumple que (A‚à™B)‚à©C=(A‚à©C)‚à™(B‚à©C)(A‚à©B)‚à™C=(A‚à™C)‚à©(B‚à™C)\\begin{aligned} &amp; (A \\cup B) \\cap C=(A \\cap C) \\cup(B \\cap C) \\\\ &amp; (A \\cap B) \\cup C=(A \\cup C) \\cap(B \\cup C) \\end{aligned}‚Äã(A‚à™B)‚à©C=(A‚à©C)‚à™(B‚à©C)(A‚à©B)‚à™C=(A‚à™C)‚à©(B‚à™C)‚Äã Ley de De Morgan: Esta ley relaciona conjuntos y sus complementos. Para dos conjuntos (eventos), E1E_1E1‚Äã y E2E_2E2‚Äã, la ley de De Morgan dice que (E1‚à™E2)‚Äæ=EÀâ1‚à©EÀâ2¬†y¬†(E1‚à©E2)‚Äæ=EÀâ1‚à™EÀâ2\\overline{\\left(E_1 \\cup E_2\\right)}=\\bar{E}_1 \\cap \\bar{E}_2 \\quad \\text { y } \\overline{\\left(E_1 \\cap E_2\\right)}=\\bar{E}_1 \\cup \\bar{E}_2(E1‚Äã‚à™E2‚Äã)‚Äã=EÀâ1‚Äã‚à©EÀâ2‚Äã¬†y¬†(E1‚Äã‚à©E2‚Äã)‚Äã=EÀâ1‚Äã‚à™EÀâ2‚Äã Generalizando (E1‚à™E2‚à™‚ãØ‚à™En)‚Äæ=EÀâ1‚à©EÀâ2‚à©‚ãØ‚à©EÀân\\overline{\\left(E_1 \\cup E_2 \\cup \\cdots \\cup E_n\\right)}=\\bar{E}_1 \\cap \\bar{E}_2 \\cap \\cdots \\cap \\bar{E}_n(E1‚Äã‚à™E2‚Äã‚à™‚ãØ‚à™En‚Äã)‚Äã=EÀâ1‚Äã‚à©EÀâ2‚Äã‚à©‚ãØ‚à©EÀân‚Äã y (E1‚à©E2‚à©‚ãØ‚à©En)‚Äæ=EÀâ1‚à™EÀâ2‚à™‚ãØ‚à™EÀân\\overline{\\left(E_1 \\cap E_2 \\cap \\cdots \\cap E_n\\right)}=\\bar{E}_1 \\cup \\bar{E}_2 \\cup \\cdots \\cup \\bar{E}_n(E1‚Äã‚à©E2‚Äã‚à©‚ãØ‚à©En‚Äã)‚Äã=EÀâ1‚Äã‚à™EÀâ2‚Äã‚à™‚ãØ‚à™EÀân‚Äã  ","version":"Next","tagName":"h3"},{"title":"Axiomas fundamentales‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#axiomas-fundamentales","content":" Los axiomas son los siguientes:  Axioma 1: Para cada evento EEE contenido en un espacio muestral SSS se tiene que P(E)‚â•0P(E) \\geq 0P(E)‚â•0 Axioma 2: La probabilidad del evento certeza SSS es P(S)=1P(S)=1P(S)=1 Axioma 3: Para dos eventos E1E_1E1‚Äã y E2E_2E2‚Äã mutuamente excluyentes (disjuntos), P(E1‚à™E2)=P(E1)+P(E2)P\\left(E_1 \\cup E_2\\right)=P\\left(E_1\\right)+P\\left(E_2\\right)P(E1‚Äã‚à™E2‚Äã)=P(E1‚Äã)+P(E2‚Äã)  ","version":"Next","tagName":"h3"},{"title":"Ley aditiva‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#ley-aditiva","content":" Sea un evento EEE y su complemento EÀâ\\bar{E}EÀâ. Por ser eventos disjuntos se tiene que  P(E‚à™EÀâ)=P(E)+P(EÀâ)P(E \\cup \\bar{E})=P(E)+P(\\bar{E})P(E‚à™EÀâ)=P(E)+P(EÀâ)  Adem√°s como (E‚à™EÀâ)=S(E \\cup \\bar{E})=S(E‚à™EÀâ)=S, se tiene que  P(EÀâ)=1‚àíP(E)P(\\bar{E})=1-P(E)P(EÀâ)=1‚àíP(E)  Por otra parte  P(E‚à©EÀâ)=P(œï)=0P(E \\cap \\bar{E})=P(\\phi)=0P(E‚à©EÀâ)=P(œï)=0  Finalmente para dos eventos cualquiera E1E_1E1‚Äã y E2E_2E2‚Äã la ley aditiva dice que  P(E1‚à™E2)=P(E1)+P(E2)‚àíP(E1‚à©E2)P\\left(E_1 \\cup E_2\\right)=P\\left(E_1\\right)+P\\left(E_2\\right)-P\\left(E_1 \\cap E_2\\right)P(E1‚Äã‚à™E2‚Äã)=P(E1‚Äã)+P(E2‚Äã)‚àíP(E1‚Äã‚à©E2‚Äã)  Esta ecuaci√≥n aplicada a la uni√≥n de tres eventos E1E_1E1‚Äã, E2E_2E2‚Äã y E3E_3E3‚Äã es  P(E1‚à™E2‚à™E3)=P[(E1‚à™E2)‚à™E3]=P(E1‚à™E2)+P(E3)‚àíP[(E1‚à™E2)‚à©E3]=P(E1)+P(E2)‚àíP(E1‚à©E2)+P(E3)‚àíP[(E1‚à©E3)‚à™(E2‚à©E3)]=P(E1)+P(E2)+P(E3)‚àíP(E1‚à©E2)‚àíP(E1‚à©E3)‚àíP(E2‚à©E3)+P(E1‚à©E2‚à©E3)\\begin{aligned} P\\left(E_1 \\cup E_2 \\cup E_3\\right)= &amp; P\\left[\\left(E_1 \\cup E_2\\right) \\cup E_3\\right] \\\\ = &amp; P\\left(E_1 \\cup E_2\\right)+P\\left(E_3\\right)-P\\left[\\left(E_1 \\cup E_2\\right) \\cap E_3\\right] \\\\ = &amp; P\\left(E_1\\right)+P\\left(E_2\\right)-P\\left(E_1 \\cap E_2\\right)+P\\left(E_3\\right)-P\\left[\\left(E_1 \\cap E_3\\right) \\cup\\left(E_2 \\cap E_3\\right)\\right] \\\\ = &amp; P\\left(E_1\\right)+P\\left(E_2\\right)+P\\left(E_3\\right)-P\\left(E_1 \\cap E_2\\right)-P\\left(E_1 \\cap E_3\\right)-P\\left(E_2 \\cap E_3\\right) \\\\ &amp; +P\\left(E_1 \\cap E_2 \\cap E_3\\right) \\end{aligned}P(E1‚Äã‚à™E2‚Äã‚à™E3‚Äã)====‚ÄãP[(E1‚Äã‚à™E2‚Äã)‚à™E3‚Äã]P(E1‚Äã‚à™E2‚Äã)+P(E3‚Äã)‚àíP[(E1‚Äã‚à™E2‚Äã)‚à©E3‚Äã]P(E1‚Äã)+P(E2‚Äã)‚àíP(E1‚Äã‚à©E2‚Äã)+P(E3‚Äã)‚àíP[(E1‚Äã‚à©E3‚Äã)‚à™(E2‚Äã‚à©E3‚Äã)]P(E1‚Äã)+P(E2‚Äã)+P(E3‚Äã)‚àíP(E1‚Äã‚à©E2‚Äã)‚àíP(E1‚Äã‚à©E3‚Äã)‚àíP(E2‚Äã‚à©E3‚Äã)+P(E1‚Äã‚à©E2‚Äã‚à©E3‚Äã)‚Äã  Para nnn eventos cualquiera, por De Morgan se tiene lo siguiente:  P(E1‚à™E2‚à™‚ãØ‚à™En)=1‚àíP(E1‚à™E2‚à™‚ãØ‚à™En‚Äæ)=1‚àíP(EÀâ1‚à©EÀâ2‚à©‚ãØ‚à©EÀân)\\begin{aligned} P\\left(E_1 \\cup E_2 \\cup \\cdots \\cup E_n\\right) &amp; =1-P\\left(\\overline{E_1 \\cup E_2 \\cup \\cdots \\cup E_n}\\right) \\\\ &amp; =1-P\\left(\\bar{E}_1 \\cap \\bar{E}_2 \\cap \\cdots \\cap \\bar{E}_n\\right) \\end{aligned}P(E1‚Äã‚à™E2‚Äã‚à™‚ãØ‚à™En‚Äã)‚Äã=1‚àíP(E1‚Äã‚à™E2‚Äã‚à™‚ãØ‚à™En‚Äã‚Äã)=1‚àíP(EÀâ1‚Äã‚à©EÀâ2‚Äã‚à©‚ãØ‚à©EÀân‚Äã)‚Äã  En el caso de E1,‚Ä¶,EnE_1, \\ldots, E_nE1‚Äã,‚Ä¶,En‚Äã sean eventos mutuamente excluyentes  P(E1‚à™E2‚à™‚ãØ‚à™En)=‚àëi=1nP(Ei)P\\left(E_1 \\cup E_2 \\cup \\cdots \\cup E_n\\right)=\\sum_{i=1}^n P\\left(E_i\\right)P(E1‚Äã‚à™E2‚Äã‚à™‚ãØ‚à™En‚Äã)=i=1‚àën‚ÄãP(Ei‚Äã)  ","version":"Next","tagName":"h3"},{"title":"M√©todos de conteo‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#m√©todos-de-conteo","content":" Cuando los espacios muestrales son finitos, basta con asignar probabilidades a cada uno de los resultados posibles para luego obtener las probabilidad de un suceso simplemente sumando las probabilidades de ocurrencia de cada resultado b√°sico que lo componen.  S={œâ1,‚Ä¶,œâN}S=\\left\\{\\omega_1, \\ldots, \\omega_N\\right\\}S={œâ1‚Äã,‚Ä¶,œâN‚Äã}  con pi=P({œâi}),i=1,‚Ä¶,Np_i=P\\left(\\left\\{\\omega_i\\right\\}\\right), i=1, \\ldots, Npi‚Äã=P({œâi‚Äã}),i=1,‚Ä¶,N. Para el caso de Probabilidad Cl√°sica se tiene que para un suceso AAA :  P(A)=#A#S=NuÀämero¬†de¬†casos¬†favorablesNuÀämero¬†de¬†casos¬†posiblesP(A)=\\frac{\\# A}{\\# S} = \\frac{\\text{N√∫mero de casos favorables}}{\\text{N√∫mero de casos posibles}}P(A)=#S#A‚Äã=NuÀämero¬†de¬†casos¬†posiblesNuÀämero¬†de¬†casos¬†favorables‚Äã  ","version":"Next","tagName":"h2"},{"title":"Principio de multiplicaci√≥n‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#principio-de-multiplicaci√≥n","content":" Si un experimento est√° compuesto de kkk experimentos con tama√±os muestrales n1,‚Ä¶,nkn_1, \\ldots, n_kn1‚Äã,‚Ä¶,nk‚Äã, entonces  #S=n1√ón2√ó‚ãØ√ónk\\# S=n_1 \\times n_2 \\times \\cdots \\times n_k#S=n1‚Äã√ón2‚Äã√ó‚ãØ√ónk‚Äã  Por ejemplo, si se tienen n1n_1n1‚Äã maneras de realizar el primer experimento, n2n_2n2‚Äã maneras de realizar el segundo experimento, y as√≠ sucesivamente, entonces el n√∫mero total de maneras de realizar el experimento compuesto es n1√ón2√ó‚ãØ√ónkn_1 \\times n_2 \\times \\cdots \\times n_kn1‚Äã√ón2‚Äã√ó‚ãØ√ónk‚Äã.  ","version":"Next","tagName":"h3"},{"title":"Permutaci√≥n‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#permutaci√≥n","content":" Consideremos un conjunto de objetos  C={c1,‚Ä¶,cn}C=\\left\\{c_1, \\ldots, c_n\\right\\}C={c1‚Äã,‚Ä¶,cn‚Äã}  y queremos seleccionar una muestra de rrr objetos. ¬øDe cu√°ntas maneras lo podemos hacer?  Muestreo Con Reemplazo: nrn^rnr.Muestreo Sin Reemplazo: n√ó(n‚àí1)√ó(n‚àí2)√ó‚ãØ√ó(n‚àír+1)n \\times(n-1) \\times(n-2) \\times \\cdots \\times(n-r+1)n√ó(n‚àí1)√ó(n‚àí2)√ó‚ãØ√ó(n‚àír+1).  La permutaci√≥n se denota como P(n,r)P(n, r)P(n,r) y se define como  P(n,r)=n√ó(n‚àí1)√ó(n‚àí2)√ó‚ãØ√ó(n‚àír+1)=n!(n‚àír)!P(n, r)=n \\times(n-1) \\times(n-2) \\times \\cdots \\times(n-r+1)=\\frac{n!}{(n-r)!}P(n,r)=n√ó(n‚àí1)√ó(n‚àí2)√ó‚ãØ√ó(n‚àír+1)=(n‚àír)!n!‚Äã  ","version":"Next","tagName":"h3"},{"title":"Combinaci√≥n‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#combinaci√≥n","content":" Consideremos un Muestreo Sin Reemplazo. Si nos interesa una muestra sin importar el orden de ingreso, la cantidad de muestras distintas de tama√±o rrr son  (nr)=n!r!√ó(n‚àír)!\\left(\\begin{array}{l} n \\\\ r \\end{array}\\right)=\\frac{n !}{r ! \\times(n-r) !}(nr‚Äã)=r!√ó(n‚àír)!n!‚Äã  Estos &quot;n√∫meros&quot; se conocen como coeficientes binomiales y tienen la siguiente propiedad  (a+b)n=‚àëk=0n(nk)akbn‚àík(a+b)^n=\\sum_{k=0}^n\\left(\\begin{array}{l} n \\\\ k \\end{array}\\right) a^k b^{n-k}(a+b)n=k=0‚àën‚Äã(nk‚Äã)akbn‚àík  ","version":"Next","tagName":"h3"},{"title":"Ordenamiento multinomial‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#ordenamiento-multinomial","content":" Queremos asignar nnn objetos a kkk grupos distintos de tama√±os n1,‚Ä¶n_1, \\ldotsn1‚Äã,‚Ä¶, nkn_knk‚Äã, con ‚àëi=1kni=n\\displaystyle\\sum_{i=1}^k n_i=ni=1‚àëk‚Äãni‚Äã=n. El n√∫mero de grupos distintos con las caracter√≠sticas dadas son  (nn1n2‚ãØnk)=n!n1!√ó‚ãØ√ónk!\\left(\\begin{array}{c} n \\\\ n_1 n_2 \\cdots n_k \\end{array}\\right)=\\frac{n !}{n_{1} ! \\times \\cdots \\times n_{k} !}(nn1‚Äãn2‚Äã‚ãØnk‚Äã‚Äã)=n1‚Äã!√ó‚ãØ√ónk‚Äã!n!‚Äã  Estos &quot;n√∫meros&quot; se conocen como ordenamientos multinomiales y tienen la siguiente propiedad  (x1+‚ãØ+xk)n=‚àën1=0n‚àën2=0n‚àín1‚ãØ‚àënk=0n‚àín1‚àí‚ãØ‚àínk‚àí1n!n1!√ó‚ãØ√ónk!x1n1√ó‚ãØ√óxknk\\left(x_1+\\cdots+x_k\\right)^n=\\sum_{n_1=0}^n \\sum_{n_2=0}^{n-n_1} \\cdots \\sum_{n_k=0}^{n-n_1-\\cdots-n_{k-1}} \\frac{n !}{n_{1} ! \\times \\cdots \\times n_{k} !} x_1^{n_1} \\times \\cdots \\times x_k^{n_k}(x1‚Äã+‚ãØ+xk‚Äã)n=n1‚Äã=0‚àën‚Äãn2‚Äã=0‚àën‚àín1‚Äã‚Äã‚ãØnk‚Äã=0‚àën‚àín1‚Äã‚àí‚ãØ‚àínk‚àí1‚Äã‚Äãn1‚Äã!√ó‚ãØ√ónk‚Äã!n!‚Äãx1n1‚Äã‚Äã√ó‚ãØ√óxknk‚Äã‚Äã  ","version":"Next","tagName":"h3"},{"title":"Probabilidad condicional‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#probabilidad-condicional","content":" Cuando la ocurrencia de un evento (o no ocurrencia) depende de otro evento, es relevante ver la probabilidad como una probabilidad condicional.  Se define la probabilidad que un evento E1E_1E1‚Äã ocurra bajo el supuesto que otro evento E2E_2E2‚Äã ocurre con certeza a  P(E1‚à£E2)=P(E1‚à©E2)P(E2)P\\left(E_1 \\mid E_2\\right)=\\frac{P\\left(E_1 \\cap E_2\\right)}{P\\left(E_2\\right)}P(E1‚Äã‚à£E2‚Äã)=P(E2‚Äã)P(E1‚Äã‚à©E2‚Äã)‚Äã  En general, la probabilidad de un evento EEE ya est√° condicionada se condiciona a la ocurrencia del evento certeza SSS:  P(E‚à£S)=P(E‚à©S)P(S)=P(E)P(E \\mid S)=\\frac{P(E \\cap S)}{P(S)}=P(E)P(E‚à£S)=P(S)P(E‚à©S)‚Äã=P(E)  Consideremos las probabilidades de un evento E1E_1E1‚Äã y su complemento EÀâ1\\bar{E}_1EÀâ1‚Äã condicionados a la ocurrencia previa de un evento E2E_2E2‚Äã.  P(E1‚à£E2)=P(E1‚à©E2)P(E2)¬†y¬†P(EÀâ1‚à£E2)=P(EÀâ1‚à©E2)P(E2)P\\left(E_1 \\mid E_2\\right)=\\frac{P\\left(E_1 \\cap E_2\\right)}{P\\left(E_2\\right)} \\quad \\text { y } \\quad P\\left(\\bar{E}_1 \\mid E_2\\right)=\\frac{P\\left(\\bar{E}_1 \\cap E_2\\right)}{P\\left(E_2\\right)}P(E1‚Äã‚à£E2‚Äã)=P(E2‚Äã)P(E1‚Äã‚à©E2‚Äã)‚Äã¬†y¬†P(EÀâ1‚Äã‚à£E2‚Äã)=P(E2‚Äã)P(EÀâ1‚Äã‚à©E2‚Äã)‚Äã  Si las sumamos tenemos que  P(EÀâ1‚à£E2)=1‚àíP(E1‚à£E2)P\\left(\\bar{E}_1 \\mid E_2\\right)=1-P\\left(E_1 \\mid E_2\\right)P(EÀâ1‚Äã‚à£E2‚Äã)=1‚àíP(E1‚Äã‚à£E2‚Äã)  ","version":"Next","tagName":"h2"},{"title":"Independencia estad√≠stica‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#independencia-estad√≠stica","content":" Dos eventos E1E_1E1‚Äã y E2E_2E2‚Äã se dice que son estad√≠sticamente independientes si la ocurrencia de un evento no depende de la ocurrencia o no ocurrencia del otro.  Es decir,  P(E1‚à£E2)=P(E1)¬†oÀä¬†P(E2‚à£E1)=P(E2)P\\left(E_1 \\mid E_2\\right)=P\\left(E_1\\right) \\text { √≥ } P\\left(E_2 \\mid E_1\\right)=P\\left(E_2\\right)P(E1‚Äã‚à£E2‚Äã)=P(E1‚Äã)¬†oÀä¬†P(E2‚Äã‚à£E1‚Äã)=P(E2‚Äã)  A partir de la ecuaci√≥n de probabilidad condicional se deduce que si E1E_1E1‚Äã y E2E_2E2‚Äã son eventos posibles entonces  P(E1‚à©E2)=P(E1‚à£E2)‚ãÖP(E2)¬†oÀä¬†P(E1‚à©E2)=P(E2‚à£E1)‚ãÖP(E1)P\\left(E_1 \\cap E_2\\right)=P\\left(E_1 \\mid E_2\\right) \\cdot P\\left(E_2\\right) \\quad \\text { √≥ } \\quad P\\left(E_1 \\cap E_2\\right)=P\\left(E_2 \\mid E_1\\right) \\cdot P\\left(E_1\\right)P(E1‚Äã‚à©E2‚Äã)=P(E1‚Äã‚à£E2‚Äã)‚ãÖP(E2‚Äã)¬†oÀä¬†P(E1‚Äã‚à©E2‚Äã)=P(E2‚Äã‚à£E1‚Äã)‚ãÖP(E1‚Äã)  Si E1E_1E1‚Äã y E2E_2E2‚Äã fuesen eventos estad√≠sticamente independientes entonces  P(E1‚à©E2)=P(E1)‚ãÖP(E2)P\\left(E_1 \\cap E_2\\right)=P\\left(E_1\\right) \\cdot P\\left(E_2\\right)P(E1‚Äã‚à©E2‚Äã)=P(E1‚Äã)‚ãÖP(E2‚Äã)  ","version":"Next","tagName":"h3"},{"title":"Ley multiplicativa‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#ley-multiplicativa","content":" Para tres eventos E1,E2E_1, E_2E1‚Äã,E2‚Äã y E3E_3E3‚Äã la ley multiplicativa implica por ejemplo que  P(E1‚à©E2‚à©E3)={P(E3‚à£E1‚à©E2)‚ãÖP(E2‚à£E1)‚ãÖP(E1)P(E1‚à©E2‚à£E3)‚ãÖP(E3)P\\left(E_1 \\cap E_2 \\cap E_3\\right)=\\left\\{\\begin{array}{l} P\\left(E_3 \\mid E_1 \\cap E_2\\right) \\cdot P\\left(E_2 \\mid E_1\\right) \\cdot P\\left(E_1\\right) \\\\ P\\left(E_1 \\cap E_2 \\mid E_3\\right) \\cdot P\\left(E_3\\right) \\end{array}\\right.P(E1‚Äã‚à©E2‚Äã‚à©E3‚Äã)={P(E3‚Äã‚à£E1‚Äã‚à©E2‚Äã)‚ãÖP(E2‚Äã‚à£E1‚Äã)‚ãÖP(E1‚Äã)P(E1‚Äã‚à©E2‚Äã‚à£E3‚Äã)‚ãÖP(E3‚Äã)‚Äã  ","version":"Next","tagName":"h2"},{"title":"Independencia‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#independencia","content":" Consideremos ahora los eventos E1,E2,‚Ä¶,EnE_1, E_2, \\ldots, E_nE1‚Äã,E2‚Äã,‚Ä¶,En‚Äã. Estos eventos se dicen mutuamente independientes si y solo si, cualquier sub-colecci√≥n de eventos de ellos Ei1,Ei2,‚Ä¶,EimE_{i 1}, E_{i 2}, \\ldots, E_{i m}Ei1‚Äã,Ei2‚Äã,‚Ä¶,Eim‚Äã cumple con la siguiente condici√≥n  P(Ei1‚à©Ei2‚à©‚ãØ‚à©Eim)=P(Ei1)√óP(Ei2)√ó‚ãØ√óP(Eim)P\\left(E_{i 1} \\cap E_{i 2} \\cap \\cdots \\cap E_{i m}\\right)=P\\left(E_{i 1}\\right) \\times P\\left(E_{i 2}\\right) \\times \\cdots \\times P\\left(E_{i m}\\right)P(Ei1‚Äã‚à©Ei2‚Äã‚à©‚ãØ‚à©Eim‚Äã)=P(Ei1‚Äã)√óP(Ei2‚Äã)√ó‚ãØ√óP(Eim‚Äã)  ","version":"Next","tagName":"h3"},{"title":"Propiedades‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#propiedades","content":" Si E1E_1E1‚Äã y E2E_2E2‚Äã son eventos estad√≠sticamente independientes, entonces EÀâ1\\bar{E}_1EÀâ1‚Äã y EÀâ2\\bar{E}_2EÀâ2‚Äã tambi√©n lo son.Si E1E_1E1‚Äã y E2E_2E2‚Äã son eventos estad√≠sticamente independientes dado un evento AAA, entoncesP(E1‚à©E2‚à£A)=P(E1‚à£A)‚ãÖP(E2‚à£A)P\\left(E_1 \\cap E_2 \\mid A\\right)=P\\left(E_1 \\mid A\\right) \\cdot P\\left(E_2 \\mid A\\right)P(E1‚Äã‚à©E2‚Äã‚à£A)=P(E1‚Äã‚à£A)‚ãÖP(E2‚Äã‚à£A)Para dos eventos cualesquiera E1E_1E1‚Äã y E2E_2E2‚Äã se tiene queP(E1‚à™E2‚à£A)=P(E1‚à£A)+P(E2‚à£A)‚àíP(E1‚à©E2‚à£A)P\\left(E_1 \\cup E_2 \\mid A\\right)=P\\left(E_1 \\mid A\\right)+P\\left(E_2 \\mid A\\right)-P\\left(E_1 \\cap E_2 \\mid A\\right)P(E1‚Äã‚à™E2‚Äã‚à£A)=P(E1‚Äã‚à£A)+P(E2‚Äã‚à£A)‚àíP(E1‚Äã‚à©E2‚Äã‚à£A)  ","version":"Next","tagName":"h3"},{"title":"Teorema de probabilidades totales‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#teorema-de-probabilidades-totales","content":" Considere nnn eventos posibles E1,E2,‚Ä¶,EnE_1, E_2, \\ldots, E_nE1‚Äã,E2‚Äã,‚Ä¶,En‚Äã colectivamente exhaustivos y mutuamente excluyentes, es decir,  ‚ãÉi=1nEi=S¬†y¬†Ei‚à©Ej=œï‚àÄi‚â†j\\bigcup_{i=1}^n E_i=S \\quad \\text { y } \\quad E_i \\cap E_j=\\phi \\quad \\forall i \\neq ji=1‚ãÉn‚ÄãEi‚Äã=S¬†y¬†Ei‚Äã‚à©Ej‚Äã=œï‚àÄiÓÄ†=j  Entonces  A=A‚à©S=A‚à©[‚ãÉi=1nEi]=‚ãÉi=1n(A‚à©Ei),A=A \\cap S=A \\cap\\left[\\bigcup_{i=1}^n E_i\\right]=\\bigcup_{i=1}^n\\left(A \\cap E_i\\right),A=A‚à©S=A‚à©[i=1‚ãÉn‚ÄãEi‚Äã]=i=1‚ãÉn‚Äã(A‚à©Ei‚Äã),  con (A‚à©E1),‚Ä¶,(A‚à©En)\\left(A \\cap E_1\\right), \\ldots,\\left(A \\cap E_n\\right)(A‚à©E1‚Äã),‚Ä¶,(A‚à©En‚Äã) eventos mutuamente excluyentes. Por lo tanto, por axioma 3 y ley multiplcativa  P(A)=‚àëi=1nP(A‚à©Ei)=‚àëi=1nP(A‚à£Ei)‚ãÖP(Ei)P(A)=\\sum_{i=1}^n P\\left(A \\cap E_i\\right)=\\sum_{i=1}^n P\\left(A \\mid E_i\\right) \\cdot P\\left(E_i\\right)P(A)=i=1‚àën‚ÄãP(A‚à©Ei‚Äã)=i=1‚àën‚ÄãP(A‚à£Ei‚Äã)‚ãÖP(Ei‚Äã)  ","version":"Next","tagName":"h2"},{"title":"Teorema de Bayes‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#teorema-de-bayes","content":" Si cada evento EjE_jEj‚Äã de la partici√≥n de SSS y el evento AAA son posibles, entonces por la ley multiplicativa se tiene que  P(A‚à£Ej)‚ãÖP(Ej)=P(Ej‚à£A)‚ãÖP(A)P\\left(A \\mid E_j\\right) \\cdot P\\left(E_j\\right)=P\\left(E_j \\mid A\\right) \\cdot P(A)P(A‚à£Ej‚Äã)‚ãÖP(Ej‚Äã)=P(Ej‚Äã‚à£A)‚ãÖP(A)  Es decir,  P(Ej‚à£A)=P(A‚à£Ej)‚ãÖP(Ej)P(A)P\\left(E_j \\mid A\\right)=\\frac{P\\left(A \\mid E_j\\right) \\cdot P\\left(E_j\\right)}{P(A)}P(Ej‚Äã‚à£A)=P(A)P(A‚à£Ej‚Äã)‚ãÖP(Ej‚Äã)‚Äã  Aplicando el teorema de probabilidades totales se tiene que  P(Ej‚à£A)=P(A‚à£Ej)‚ãÖP(Ej)‚àëi=1nP(A‚à£Ei)‚ãÖP(Ei)=P(A‚à£Ej)‚ãÖP(Ej)P(A)P\\left(E_j \\mid A\\right)=\\frac{P\\left(A \\mid E_j\\right) \\cdot P\\left(E_j\\right)}{\\sum_{i=1}^n P\\left(A \\mid E_i\\right) \\cdot P\\left(E_i\\right)} = \\frac{P\\left(A \\mid E_j\\right) \\cdot P\\left(E_j\\right)}{P(A)}P(Ej‚Äã‚à£A)=‚àëi=1n‚ÄãP(A‚à£Ei‚Äã)‚ãÖP(Ei‚Äã)P(A‚à£Ej‚Äã)‚ãÖP(Ej‚Äã)‚Äã=P(A)P(A‚à£Ej‚Äã)‚ãÖP(Ej‚Äã)‚Äã  Este resultado se conoce como el Teorema de Bayes. En general, una f√≥rmula del teorema de Bayes para dos eventos AAA y BBB es  P(A‚à£B)=P(B‚à£A)‚ãÖP(A)P(B)P\\left(A \\mid B\\right)=\\frac{P\\left(B \\mid A\\right) \\cdot P(A)}{P(B)}P(A‚à£B)=P(B)P(B‚à£A)‚ãÖP(A)‚Äã  Diagrama de √°rbol para dos eventos A y B  ","version":"Next","tagName":"h2"},{"title":"Variables y distribuciones‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#variables-y-distribuciones","content":" ","version":"Next","tagName":"h2"},{"title":"Variables aleatorias‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#variables-aleatorias","content":" Una variable aleatoria es el veh√≠culo matem√°tico para representar un evento en t√©rminos anal√≠ticos. El valor de una variable aleatoria puede estar definida para un conjunto de posibles valores.  Si XXX es una variable aleatoria, entonces  X=x,X&lt;x,X&gt;xX=x, \\quad X&lt;x, \\quad X&gt;xX=x,X&lt;x,X&gt;x  representa un evento, donde (a&lt;X&lt;b)(a&lt;X&lt;b)(a&lt;X&lt;b) es el rango de valores posibles de XXX. La asignaci√≥n num√©rica puede ser natural o artificial.  Formalmente, una variable aleatoria puede ser considerada como una funci√≥n o regla sobre los eventos del espacio muestral a un sistema num√©rico (o l√≠nea real).    As√≠, los eventos E1E_1E1‚Äã y E2E_2E2‚Äã pueden corresponder a  E1=(a&lt;X‚â§b)E2=(c&lt;X‚â§d)E1‚à™E2‚Äæ=(X‚â§a)‚à™(X&gt;d)E1‚à©E2=(c&lt;X‚â§b)\\begin{aligned} E_1 &amp; =(a&lt;X \\leq b) \\\\ E_2 &amp; =(c&lt;X \\leq d) \\\\ \\overline{E_1 \\cup E_2} &amp; =(X \\leq a) \\cup(X&gt;d) \\\\ E_1 \\cap E_2 &amp; =(c&lt;X \\leq b) \\end{aligned}E1‚ÄãE2‚ÄãE1‚Äã‚à™E2‚Äã‚ÄãE1‚Äã‚à©E2‚Äã‚Äã=(a&lt;X‚â§b)=(c&lt;X‚â§d)=(X‚â§a)‚à™(X&gt;d)=(c&lt;X‚â§b)‚Äã  Una variable aleatoria puede ser discreta o continua.  ","version":"Next","tagName":"h3"},{"title":"Distribuciones de probabilidad‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#distribuciones-de-probabilidad","content":" Para los valores o rango de valores que puede tomar una variable aleatoria tienen asociados una probabilidad especifica o medidas de probabilidad. La regla que asigna las medidas de probabilidad se denomina distribuci√≥n o ley de probabilidad.  Si XXX es variable aleatoria, la distribuci√≥n de probabilidad puede ser descrita por su funci√≥n de distribuci√≥n de probabilidad acumulada denotada por:  FX(x)=P(X‚â§x)¬†para¬†todo¬†x‚ààRF_X(x)=P(X \\leq x) \\text { para todo } x \\in \\mathbb{R}FX‚Äã(x)=P(X‚â§x)¬†para¬†todo¬†x‚ààR  Si XXX es una variable aleatoria discreta, entonces esta funci√≥n puede ser expresada a trav√©s de la funci√≥n de probabilidad &quot;puntual&quot; denotada por  pX(x)=P(X=x)p_X(x)=P(X=x)pX‚Äã(x)=P(X=x)  As√≠,  FX(x)=‚àëxi‚â§xP(X=xi)=‚àëxi‚â§xpX(xi)F_X(x)=\\sum_{x_i \\leq x} P\\left(X=x_i\\right)=\\sum_{x_i \\leq x} p_X\\left(x_i\\right)FX‚Äã(x)=xi‚Äã‚â§x‚àë‚ÄãP(X=xi‚Äã)=xi‚Äã‚â§x‚àë‚ÄãpX‚Äã(xi‚Äã)  con xi‚ààŒòXx_i \\in \\Theta_Xxi‚Äã‚ààŒòX‚Äã (soporte de X)\\left.X\\right)X).  Ahora, si XXX es una variable aleatoria continua, las probabilidades est√°n asociadas a intervalos de xxx. En este caso se define la funci√≥n de densidad fX(x)f_X(x)fX‚Äã(x) tal que  P(a&lt;X‚â§b)=‚à´abfX(x)dxP(a&lt;X \\leq b)=\\int_a^b f_X(x) d xP(a&lt;X‚â§b)=‚à´ab‚ÄãfX‚Äã(x)dx  y  FX(x)=P(X‚â§x)=‚à´‚àí‚àûxfX(t)dtF_X(x)=P(X \\leq x)=\\int_{-\\infty}^x f_X(t) d tFX‚Äã(x)=P(X‚â§x)=‚à´‚àí‚àûx‚ÄãfX‚Äã(t)dt  con  fX(x)=ddxFX(x)f_X(x)=\\frac{d}{d x} F_X(x)fX‚Äã(x)=dxd‚ÄãFX‚Äã(x)  Notar que  P(x&lt;X‚â§x+dx)=fX(x)dxP(x&lt;X \\leq x+d x)=f_X(x) d xP(x&lt;X‚â§x+dx)=fX‚Äã(x)dx  Caso discreto y continuo  Caso mixto  ","version":"Next","tagName":"h3"},{"title":"Propiedades‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#propiedades-1","content":" FX(‚àí‚àû)=0F_X(-\\infty)=0FX‚Äã(‚àí‚àû)=0 y FX(‚àû)=1F_X(\\infty)=1FX‚Äã(‚àû)=1.FX(x)‚â•0F_X(x) \\geq 0FX‚Äã(x)‚â•0 para todo valor de xxx y es no decreciente.FX(x)F_X(x)FX‚Äã(x) es continua por la derecha  Para el caso continuo, la ecuaci√≥n la podemos escribir como  P(a&lt;X‚â§b)=‚à´‚àí‚àûbfX(x)dx‚àí‚à´‚àí‚àûafX(x)dxP(a&lt;X \\leq b)=\\int_{-\\infty}^b f_X(x) d x-\\int_{-\\infty}^a f_X(x) d xP(a&lt;X‚â§b)=‚à´‚àí‚àûb‚ÄãfX‚Äã(x)dx‚àí‚à´‚àí‚àûa‚ÄãfX‚Äã(x)dx  mientras que en el caso discreto  P(a&lt;X‚â§b)=‚àëxi‚â§bpX(xi)‚àí‚àëxi‚â§apX(xi)P(a&lt;X \\leq b)=\\sum_{x_i \\leq b} p_X\\left(x_i\\right)-\\sum_{x_i \\leq a} p_X\\left(x_i\\right)P(a&lt;X‚â§b)=xi‚Äã‚â§b‚àë‚ÄãpX‚Äã(xi‚Äã)‚àíxi‚Äã‚â§a‚àë‚ÄãpX‚Äã(xi‚Äã)  es decir, para ambos casos  P(a&lt;X‚â§b)=FX(b)‚àíFX(a)P(a&lt;X \\leq b)=F_X(b)-F_X(a)P(a&lt;X‚â§b)=FX‚Äã(b)‚àíFX‚Äã(a)  ","version":"Next","tagName":"h3"},{"title":"Medidas descriptivas de una variable aleatoria‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#medidas-descriptivas-de-una-variable-aleatoria","content":" Una variable aleatoria puede ser descrita totalmente por su funci√≥n de distribuci√≥n de probabilidad o de densidad, o bien por su funci√≥n de distribuci√≥n de probabilidad acumulada. Sin embargo, en la pr√°ctica la forma exacta puede no ser totalmente conocida.  En tales casos se requieren ciertas &quot;medidas&quot; para tener una idea de la forma de la distribuci√≥n.  ","version":"Next","tagName":"h2"},{"title":"Medidas centrales‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#medidas-centrales","content":" En el rango de posibles valores de una variable aleatoria, existe un inter√©s natural con respecto a los valores centrales, por ejemplo, el promedio.  Consideremos una variable aleatoria XXX con soporte ŒòX\\Theta_XŒòX‚Äã. Como cada valor de ŒòX\\Theta_XŒòX‚Äã tiene una medida de probabilidad, el promedio ponderado es de especial inter√©s.  Valor esperado‚Äã  Al promedio ponderado se le llama tambi√©n valor medio o valor esperado de la variable aleatoria XXX. Para una variable aleatoria XXX se define el valor esperado, ŒºX\\mu_XŒºX‚Äã, como:  ŒºX=E(X)={‚àëx‚ààŒòXx‚ãÖpX(x),¬†Caso¬†Discreto¬†‚à´‚àí‚àû‚àûx‚ãÖfX(x)dx,¬†Caso¬†Continuo¬†\\mu_X=\\mathrm{E}(X)= \\begin{cases}\\displaystyle\\sum_{x \\in \\Theta_X} x \\cdot p_X(x), &amp; \\text { Caso Discreto } \\\\[20pt] \\displaystyle\\int_{-\\infty}^{\\infty} x \\cdot f_X(x) d x, &amp; \\text { Caso Continuo }\\end{cases}ŒºX‚Äã=E(X)=‚é©‚é®‚éß‚Äãx‚ààŒòX‚Äã‚àë‚Äãx‚ãÖpX‚Äã(x),‚à´‚àí‚àû‚àû‚Äãx‚ãÖfX‚Äã(x)dx,‚Äã¬†Caso¬†Discreto Caso¬†Continuo¬†‚Äã  Este valor existe siempre y cuando  ‚àëx‚ààŒòX‚à£x‚à£‚ãÖpX(x)&lt;‚àû‚àò‚à´‚àí‚àû‚àû‚à£x‚à£‚ãÖfX(x)dx&lt;‚àû\\sum_{x \\in \\Theta_X}|x| \\cdot p_X(x)&lt;\\infty \\quad \\circ \\quad \\int_{-\\infty}^{\\infty}|x| \\cdot f_X(x) d x&lt;\\inftyx‚ààŒòX‚Äã‚àë‚Äã‚à£x‚à£‚ãÖpX‚Äã(x)&lt;‚àû‚àò‚à´‚àí‚àû‚àû‚Äã‚à£x‚à£‚ãÖfX‚Äã(x)dx&lt;‚àû  Moda‚Äã  Es el valor m√°s frecuente o con mayor probabilidad de ocurrencia. Para los casos discretos y continuos, tenemos que  ¬†Caso¬†Discreto: Moda¬†=max‚Å°x‚ààŒòXpX(x)¬†Caso¬†Continuo: Moda¬†=max‚Å°x‚ààŒòXfX(x)\\begin{aligned} \\text { Caso Discreto: } &amp; \\quad \\text { Moda }=\\max _{x \\in \\Theta_X} p_X(x) \\\\ \\text { Caso Continuo: } &amp; \\quad \\text { Moda }=\\max _{x \\in \\Theta_X} f_X(x) \\end{aligned}¬†Caso¬†Discreto: Caso¬†Continuo:¬†‚Äã¬†Moda¬†=x‚ààŒòX‚Äãmax‚ÄãpX‚Äã(x)¬†Moda¬†=x‚ààŒòX‚Äãmax‚ÄãfX‚Äã(x)‚Äã  Mediana‚Äã  Sea xmed¬†x_{\\text {med }}xmed¬†‚Äã el valor que toma la mediana, entonces  FX(xmed¬†)=1/2F_X\\left(x_{\\text {med }}\\right)=1 / 2FX‚Äã(xmed¬†‚Äã)=1/2  En resumen, el valor esperado de una variable aleatoria es un valor promedio que puede ser visto como un indicador del valor central de la distribuci√≥n de probabilidad, por esta raz√≥n se considera como un par√°metro de localizaci√≥n.  Por otra parte, la mediana y la moda de una distribuci√≥n tambi√©n son par√°metros de localizaci√≥n que no necesariamente son iguales a la media.  Nota Cuando la distribuci√≥n es sim√©trica, estas tres medidas son parecidas.  ","version":"Next","tagName":"h3"},{"title":"Medidas de posici√≥n‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#medidas-de-posici√≥n","content":" Percentiles‚Äã  Si xpx_pxp‚Äã es el valor que toma el percentil p√ó100%p \\times 100 \\%p√ó100%, entonces FX(xp)=F_X\\left(x_p\\right)=FX‚Äã(xp‚Äã)= ppp.  Algunos casos particulares de percentil son: quintiles, cuartiles, deciles, mediana.  Nota Los valores para cada tipo de percentil son: Quintiles: p=0.2p=0.2p=0.2Cuartiles: p=0.25p=0.25p=0.25Deciles: p=0.1p=0.1p=0.1Mediana: p=0.5p=0.5p=0.5  Esperanza matem√°tica‚Äã  La noci√≥n del valor esperado como un promedio ponderado puede ser generalizado para funciones de la variable aleatoria XXX. Dada una funci√≥n g(X)g(X)g(X), entonces el valor esperado de esta puede ser obtenido como:  E[g(X)]={‚àëx‚ààŒòXg(x)‚ãÖpX(x),¬†Caso¬†Discreto¬†‚à´‚àí‚àû‚àûg(x)‚ãÖfX(x)dx,¬†Caso¬†Continuo¬†E[g(X)]= \\begin{cases}\\displaystyle\\sum_{x \\in \\Theta_X} g(x) \\cdot p_X(x), &amp; \\text { Caso Discreto } \\\\[20pt] \\displaystyle\\int_{-\\infty}^{\\infty} g(x) \\cdot f_X(x) d x, &amp; \\text { Caso Continuo }\\end{cases}E[g(X)]=‚é©‚é®‚éß‚Äãx‚ààŒòX‚Äã‚àë‚Äãg(x)‚ãÖpX‚Äã(x),‚à´‚àí‚àû‚àû‚Äãg(x)‚ãÖfX‚Äã(x)dx,‚Äã¬†Caso¬†Discreto Caso¬†Continuo¬†‚Äã  Funci√≥n generadora de momentos‚Äã  La funci√≥n generadora de momentos de una variable aleatoria XXX se define como  MX(t)=E[exp‚Å°(tX)]M_X(t)=\\mathrm{E}[\\exp (t X)]MX‚Äã(t)=E[exp(tX)]  Esta funci√≥n puede no estar definida para algunos valores de ttt, pero si existe en un intervalo abierto que contenga al cero, entonces esta funci√≥n tiene la propiedad de determinar la distribuci√≥n de probabilidad de XXX.  Cuando esto √∫ltimo ocurra, esta funci√≥n permite obtener el rrr-√©simo momento de XXX de la siguiente forma  M(r)(0)=E(Xr)M^{(r)}(0)=\\mathrm{E}\\left(X^r\\right)M(r)(0)=E(Xr)  ","version":"Next","tagName":"h3"},{"title":"Medidas de dispersi√≥n‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#medidas-de-dispersi√≥n","content":" Es de inter√©s cuantificar el nivel de dispersi√≥n que tienen una variable aleatoria con respecto a un valor de referencia. Por ejemplo, nos podr√≠a interesar la distancia esperada de los valores de una variable aleatoria XXX con respeto al valor esperado ŒºX\\mu_XŒºX‚Äã, es decir, E[(X‚àíŒºX)]\\mathrm{E}\\left[\\left(X-\\mu_X\\right)\\right]E[(X‚àíŒºX‚Äã)].  Esta idea de dispersi√≥n tiene el problema que siempre da como resultado cero.  Varianza‚Äã  Una alternativa es utilizar la definici√≥n de varianza, es decir  œÉX2=Var‚Å°(X)=E[(X‚àíŒºX)2]={‚àëx‚ààŒòX(x‚àíŒºX)2‚ãÖpX(x),¬†Caso¬†Discreto¬†‚à´‚àí‚àû‚àû(x‚àíŒºX)2‚ãÖfX(x)dx,¬†Caso¬†Continuo¬†=E(X2)‚àíŒºX2\\begin{aligned} \\sigma_X^2 &amp; =\\operatorname{Var}(X)=\\mathrm{E}\\left[\\left(X-\\mu_X\\right)^2\\right] \\\\ &amp; = \\begin{cases} \\displaystyle\\sum_{x \\in \\Theta_X}\\left(x-\\mu_X\\right)^2 \\cdot p_X(x), &amp; \\text { Caso Discreto } \\\\[20pt] \\displaystyle\\int_{-\\infty}^{\\infty}\\left(x-\\mu_X\\right)^2 \\cdot f_X(x) d x, &amp; \\text { Caso Continuo }\\end{cases} \\\\[30pt] &amp; =\\mathrm{E}\\left(X^2\\right)-\\mu_X^2 \\end{aligned}œÉX2‚Äã‚Äã=Var(X)=E[(X‚àíŒºX‚Äã)2]=‚é©‚é®‚éß‚Äãx‚ààŒòX‚Äã‚àë‚Äã(x‚àíŒºX‚Äã)2‚ãÖpX‚Äã(x),‚à´‚àí‚àû‚àû‚Äã(x‚àíŒºX‚Äã)2‚ãÖfX‚Äã(x)dx,‚Äã¬†Caso¬†Discreto Caso¬†Continuo¬†‚Äã=E(X2)‚àíŒºX2‚Äã‚Äã  Desviaci√≥n est√°ndar‚Äã  En t√©rminos de dimensionalidad, es conveniente utilizar la desviaci√≥n estandar, es decir,  œÉX=Var‚Å°(X)\\sigma_X=\\sqrt{\\operatorname{Var}(X)}œÉX‚Äã=Var(X)‚Äã  Coeficiente de variaci√≥n‚Äã  Ahora, si ŒºX&gt;0\\mu_X&gt;0ŒºX‚Äã&gt;0, una medida adimensional de la variabilidad es el coeficiente de variaci√≥n (c.o.v)  Œ¥X=œÉXŒºX\\delta_X=\\frac{\\sigma_X}{\\mu_X}Œ¥X‚Äã=ŒºX‚ÄãœÉX‚Äã‚Äã  Rango y IQR‚Äã  Las definiciones para el rango y el rango intercuart√≠lico (IQR) son  ¬†Rango¬†=max‚Å°‚àímin‚Å°IQR=x0.75‚àíx0.25\\begin{aligned} \\text { Rango } &amp; =\\max -\\min \\\\ \\mathrm{IQR} &amp; =x_{0.75}-x_{0.25} \\end{aligned}¬†Rango¬†IQR‚Äã=max‚àímin=x0.75‚Äã‚àíx0.25‚Äã‚Äã  ","version":"Next","tagName":"h3"},{"title":"Medidas de asimetr√≠a‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#medidas-de-asimetr√≠a","content":" Skewness‚Äã  Se define una medida de asimetr√≠a (skewness) corresponde al tercer momento central:  E[(X‚àíŒºX)3]={‚àëxi‚ààŒòX(xi‚àíŒºX)3‚ãÖpX(xi),¬†Caso¬†Discreto¬†‚à´‚àí‚àû‚àû(x‚àíŒºX)3‚ãÖfX(x)dx,¬†Caso¬†Continuo¬†\\mathrm{E}\\left[\\left(X-\\mu_X\\right)^3\\right]= \\begin{cases} \\displaystyle\\sum_{x_i \\in \\Theta_X}\\left(x_i-\\mu_X\\right)^3 \\cdot p_X\\left(x_i\\right), &amp; \\text { Caso Discreto } \\\\[20pt] \\displaystyle\\int_{-\\infty}^{\\infty}\\left(x-\\mu_X\\right)^3 \\cdot f_X(x) d x, &amp; \\text { Caso Continuo }\\end{cases}E[(X‚àíŒºX‚Äã)3]=‚é©‚é®‚éß‚Äãxi‚Äã‚ààŒòX‚Äã‚àë‚Äã(xi‚Äã‚àíŒºX‚Äã)3‚ãÖpX‚Äã(xi‚Äã),‚à´‚àí‚àû‚àû‚Äã(x‚àíŒºX‚Äã)3‚ãÖfX‚Äã(x)dx,‚Äã¬†Caso¬†Discreto Caso¬†Continuo¬†‚Äã  Coeficiente de asimetr√≠a‚Äã  Una medida conveniente es el coeficiente de asimetr√≠a que se define como:  Œ∏X=E[(X‚àíŒºX)3]œÉX3\\theta_X=\\frac{E\\left[\\left(X-\\mu_X\\right)^3\\right]}{\\sigma_X^3}Œ∏X‚Äã=œÉX3‚ÄãE[(X‚àíŒºX‚Äã)3]‚Äã  Skewness  ","version":"Next","tagName":"h3"},{"title":"Medidas de curtosis‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#medidas-de-curtosis","content":" Curtosis‚Äã  Finalmente, el cuarto momento central se conoce como la curtosis  E[(X‚àíŒºX)4]={‚àëxi‚ààŒòX(xi‚àíŒºX)4‚ãÖpX(xi),¬†Caso¬†Discreto¬†‚à´‚àû‚àû(x‚àíŒºX)4‚ãÖfX(x)dx,¬†Caso¬†Continuo¬†\\mathrm{E}\\left[\\left(X-\\mu_X\\right)^4\\right]= \\begin{cases} \\displaystyle\\sum_{x_i \\in \\Theta_X}\\left(x_i-\\mu_X\\right)^4 \\cdot p_X\\left(x_i\\right), &amp; \\text { Caso Discreto } \\\\[20pt] \\displaystyle\\int_{\\infty}^{\\infty}\\left(x-\\mu_X\\right)^4 \\cdot f_X(x) d x, &amp; \\text { Caso Continuo }\\end{cases}E[(X‚àíŒºX‚Äã)4]=‚é©‚é®‚éß‚Äãxi‚Äã‚ààŒòX‚Äã‚àë‚Äã(xi‚Äã‚àíŒºX‚Äã)4‚ãÖpX‚Äã(xi‚Äã),‚à´‚àû‚àû‚Äã(x‚àíŒºX‚Äã)4‚ãÖfX‚Äã(x)dx,‚Äã¬†Caso¬†Discreto Caso¬†Continuo¬†‚Äã  que es una medida del &quot;apuntamiento&quot; o &quot;achatamiento&quot; de la distribuci√≥n de probabilidad o de densidad.  Coeficiente de curtosis‚Äã  Usualmente se prefiere el coeficiente de curtosis  KX=E[(X‚àíŒºX)4]œÉX4‚àí3K_X=\\frac{E\\left[\\left(X-\\mu_X\\right)^4\\right]}{\\sigma_X^4}-3KX‚Äã=œÉX4‚ÄãE[(X‚àíŒºX‚Äã)4]‚Äã‚àí3  ","version":"Next","tagName":"h3"},{"title":"Distribuciones de probabilidad‚Äã","type":1,"pageTitle":"Probabilidades y Estad√≠stica","url":"/apuntes-fundamentals/docs/Matem√°ticas/probabilidades_estadistica#distribuciones-de-probabilidad-1","content":"","version":"Next","tagName":"h2"}],"options":{"languages":["en","es"],"id":"default"}}